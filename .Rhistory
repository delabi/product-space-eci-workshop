filter(region_col=='Saudi Arabia', time_col==2000) %>%
arrange(desc(RCAcpt)) %>%
select(product_col,RCAcpt) %>%
head(n=5)
df_rca$Mcp <- 0
df_rca[df_rca$RCAcpt>1, 'Mcp'] <- 1
calc_cppt <- function(data,region_col,product_col) {
# create product_col_2 column (to create all combinations of products within columns)
data$product_col_1 <- data$product_col
data$product_col_2 <- data$product_col_1
# create all product combinations within countries
print('creating combinations')
dft3 <- data %>% group_by(region_col) %>% complete(product_col_1, product_col_2)
print('combinations ready')
# drop diagonal
dft3 <- filter(dft3,product_col_1!=product_col_2)
# calculate N of times that {product_col}s occur together
dft3$count = 1
dft3 <- dft3 %>%
group_by(product_col_1,product_col_2) %>%
summarise(Cpp = sum(count))
# calculate ubiquity
df_ub <- data %>%
group_by(product_col) %>%
summarize(Mcp = sum(Mcp))
# Merge ubiquities of product 1 and 2 into cpp matrix
df_ub <- df_ub %>%
rename(product_col_1 = product_col)
dft3 <- left_join(dft3,df_ub,by=c('product_col_1'))
df_ub <- df_ub %>%
rename(product_col_2 = product_col_1)
dft3 <- left_join(dft3,df_ub,by=c('product_col_2'))
# Take minimum of conditional probabilities
dft3$kpi = dft3$Cpp/dft3$Mcp.x
dft3$kpj = dft3$Cpp/dft3$Mcp.y
dft3$phi = dft3$kpi
dft3 <- dft3 %>%
mutate(phi = ifelse(kpj < kpi, kpj ,kpi))
############
return(dft3)
}
# keep only year 1995 and only country-product combinations where Mcp == 1 (thus RCAcpt > 1)
dft <- filter(df_rca,time_col==1995,Mcp==1)
# calculate cppt
df_cppt <- calc_cppt(data=dft,region_col,product_col)
print('cppt product co-occurences and proximities dataframe ready')
df_cppt %>%
arrange(desc(Cpp)) %>%
head(n=10)
df_cppt %>%
arrange(desc(phi)) %>%
head(n=10)
print('loading patent data')
# load STATA file into R directly from URL (using the 'foreign' library)
dfp <- read.dta('https://www.dropbox.com/s/nwox3dznoupzm0q/patstat_year_country_tech_inventor_locations.dta?dl=1')
#dfp <- read.dta('~/Dropbox/proj/org_zhtml_projects/product-space-eci-workshop/files/patstat_year_country_tech/patstat_year_country_tech_inventor_locations.dta')
print('patent data loaded')
sample_n(dfp,10)
min(dfp$year)
max(dfp$year)
print('Unique N of counties:')
length(unique(dfp$country_name))
print('Unique N of technologies:')
length(unique(dfp$tech))
# rename columns accordingly
dfp_rca <- dfp %>%
rename(time_col = year,
region_col = country_name,
product_col = tech,
value_col = count)
# calculate RCA
dfp_rca <- calc_rca(data=dfp_rca,region_col,product_col,time_col,value_col)
print('patent rcas ready')
countries <- list("Japan", "Germany")
years <- list(1960, 2010)
for (country in countries) {
for (year in years) {
dft <- dfp_rca %>%
filter(region_col == country, time_col == year) %>%
arrange(desc(RCAcpt)) %>%
head
print(dft)
}
}
# Define Mcp
dfp_rca$Mcp = 0
dfp_rca <- dfp_rca %>%
mutate(Mcp = ifelse(RCAcpt> 1, 1,0))
# Keep only years 2010 and only country-product combinations where Mcp == 1 (thus RCAcp > 1)
dft <-  dfp_rca %>%
filter(time_col==2010,Mcp==1)
# Calculate cppt
dfp_cppt <- calc_cppt(data=dft,region_col,product_col)
print('cppt patent co-occurences and proximities dataframe ready')
# Show most proximate technologies
dfp_cppt %>%
arrange(desc(phi)) %>%
head(10)
# load csv file into R directly from URL
print('loading patent data')
dfp <- read.csv('https://www.dropbox.com/s/th4zqkmuofmg4u3/patentview_class_2022.csv?dl=1')
#dfp <- read.csv('~/Dropbox/proj/odyssey_from/patentview_class_2022.csv')
print('patent data loaded')
sample_n(dfp,10)
min(dfp$year)
max(dfp$year)
print('Unique N of counties:')
length(unique(dfp$region))
print('Unique N of technologies:')
length(unique(dfp$tech))
# rename columns accordingly
dfp_rca <- dfp %>%
rename(time_col = year,
region_col = region,
product_col = tech,
value_col = count)
# calculate RCA
# -- keep 1980 and 2017
dfp_rca <- dfp_rca %>% filter(time_col==1980 | time_col == 2017)
# -- calculate
dfp_rca <- calc_rca(data=dfp_rca,region_col,product_col,time_col,value_col)
print('patent rcas ready')
# -- minimal 5 patents
#regions <- list("CA > Santa Clara", "MI > Wayne")
regions <- list('CA > Santa Clara > San Jose','MI > Wayne > Detroit')
years <- list(1980, 2017)
for (region in regions) {
for (year in years) {
dft <- dfp_rca %>%
filter(grepl(region, region_col),time_col==year,value_col>5) %>%
arrange(desc(RCAcpt)) %>%
head
print(dft)
}
}
# Define Mcp
dfp_rca$Mcp = 0
dfp_rca <- dfp_rca %>%
mutate(Mcp = ifelse(RCAcpt> 1, 1,0))
# Keep only years 2010 and only country-product combinations where Mcp == 1 (thus RCAcp > 1)
dft <-  dfp_rca %>%
filter(time_col==2017,Mcp==1)
# Calculate cppt
dfp_cppt <- calc_cppt(data=dft,region_col,product_col)
print('df_cppt ready')
print('cppt patent co-occurences and proximities dataframe ready')
# Show most proximate technologies
dfp_cppt %>%
arrange(desc(phi)) %>%
head(10)
COUNTRY_STRING <- 'Saudi Arabia'
df_ps <- df_rca %>%
filter(region_col==COUNTRY_STRING)
# Cross-check
if (dim(df_ps)[1]==0) {
print('Country string set above does not exist in data, typed correctly?')
STOP
}
df_ps <- df_rca %>%
filter(region_col==COUNTRY_STRING, time_col==2005,RCAcpt>1,value_col > 4000000) %>%
select(product_col,value_col,product_code)
os <- import("os")
os$getcwd()
# store df_ps dataframe in R's temporary folder before loading it into Python
file_name <- tempfile(fileext = ".csv")
write.csv(df_ps, file=file_name,row.names=FALSE)
# Call the python function from R
source_python('https://raw.githubusercontent.com/cid-harvard/py-productspace/master/create_product_space_v2.py')
# Filename of product space image (saved in R's temporary folder)
network_image_file_name <- tempfile(fileext=".png")
# To add R variables as Python parameters, we'll use the glue library
string_python <- glue("create_product_space(df_plot_dataframe_filename ='{file_name}', \\\
df_plot_node_col = 'product_code', \\\
df_node_size_col = 'value_col', \\\
output_image_file ='{network_image_file_name}')"
)
# Run the python string
py_run_string(string_python)
sprintf('product space image saved in %s',network_image_file_name)
# Plot the product space now
# -- load png file
pp <- readPNG(network_image_file_name)
# -- enlarge plot area in Jupyter Notebook
options(repr.plot.width=15, repr.plot.height=15)
# -- plot, enlarge width / height for higher resolution
grid::grid.raster(pp,width=1.8,height=1.8)
print('the network can be saved as an image locally by right clicking on it in the notebook
and clicking "Save Image", or by editing the output_image_file parameter above')
# select only year 2000
dft <- df_orig %>% filter(year==2000) %>% select (country_name,product_name,export_value)
# rename columns accordingly
dft <- dft %>%
rename(country = country_name,
product = product_name,
value = export_value)
# calculate the Balassa index (rca, 1 if > 1)
bi <- balassa_index(dft)
# calculate eci / pci, using reflections here: same values as py-ecomplexity package
cm <- complexity_measures(bi,method='reflections')
# convert to tibble, add country names, sort from most to least complex
# -- xci labels are set with setNames (extract with 'names')
df_eci <- cm$complexity_index_country %>%
as_tibble() %>%
mutate(country = names(cm$complexity_index_country)) %>%
rename(eci = value)
# same procedure for products (pci)
df_pci <- cm$complexity_index_product %>%
as_tibble() %>%
mutate(product = names(cm$complexity_index_product)) %>%
rename(pci= value)
# add product codes as well to df_pci
df_product_codes <- df_orig %>%
select(product_name,product_code) %>%
distinct(product_name, .keep_all= TRUE) # drop_duplicates in pandas
df_pci <- left_join(df_pci,df_product_codes,by=c('product'='product_name'))
#########
print('eci, pci dataframes ready')
df_eci %>% arrange(desc(eci)) %>% head
df_pci %>% arrange(desc(pci)) %>% head
# Complexity by destination
print('loading data')
#df_ukr <- read_csv(file='~/Dropbox/proj/org_zhtml_projects/product-space-eci-workshop/files/ukr_exports_per_destination.csv')
df_ukr <- read_csv(file='https://www.dropbox.com/s/megm8qzn3jcwnqz/ukr_exports_per_destination.csv?dl=1')
print('loaded')
# show sample of dataset
sample_n(df_ukr,10)
# add leading zero if 3-digit
df_ukr$len_hs_product_code = str_length(df_ukr$hs_product_code)
df_ukr <- df_ukr %>%
mutate(hs_product_code = ifelse(len_hs_product_code == 3, paste('0',hs_product_code,sep=""),hs_product_code))
# strip leading / trailing spaces
df_ukr$hs_product_code <- trimws(df_ukr$hs_product_code, which = c("both"))
# merge
df_ukr <- left_join(df_ukr, df_pci, by = c("hs_product_code" = "product_code"))
calc_ecimc <- function(data,origin_col,destination_col,product_col,value_col,pci_col) {
dft <- data
# total exports by exporter-importer
dft <- dft %>%
group_by(origin_col,destination_col) %>%
mutate(export_value_cot = sum(value_col))
# sum of pci per export
dft$pci_x_export = dft$pci_col * dft$value_col
dft <- dft %>%
group_by(origin_col,destination_col) %>%
mutate(pci_x_export_sum = sum(pci_x_export))
dft$eciMc = dft$pci_x_export_sum / dft$export_value_cot
dft <- dft %>%
distinct(origin_col,destination_col, .keep_all= TRUE)
dft <- dft %>% select(origin_col,destination_col,eciMc)
return(dft)
}
print('ecimc function defined')
df_ukr_ecimc <- df_ukr %>%
rename(origin_col = location_code,
destination_col = partner_code,
product_col = hs_product_code,
value_col = export_value,
pci_col = pci
)
# calculate ecimc
df_ukr_ecimc <- calc_ecimc(data=df_ukr_ecimc,origin_col,destination_col,product_col,value_col,pci_col)
print('dataset eci weighted ready, sample below')
head(df_ukr_ecimc)
print ('need to install highcharter / maps but takes some time on google co-lab, hence not done at beginning')
###################
###################
ptm <- proc.time()
print('installing highcharter')
install.packages('highcharter',verbose=TRUE)
install.packages('highcharter') # slow install (in colab)
proc.time() - ptm
ptm <- proc.time()
print('installing maps')
install.packages('maps',verbose=TRUE)
install.packages('maps')
proc.time() - ptm
###################
###################
library('highcharter')
library('maps')
df_ukr_ecimc_map <- df_ukr_ecimc %>%
rename("iso-a3"="destination_col")
hcmap(
map = "custom/world-highres3", # high resolution world map
# eci in 85th percentile
data = filter(df_ukr_ecimc_map,eciMc>quantile(df_ukr_ecimc_map$eciMc,probs=c(0.85),na.rm=TRUE)),
joinBy = "iso-a3",
value = "eciMc",
showInLegend = FALSE, # hide legend
#nullColor = "#DADADA",
download_map_data = TRUE
) %>% hc_colorAxis(minColor = "orange", maxColor = "red")
head(df_ukr_ecimc)
df_orig %>%
filter(country_name=='Ukraine',year==2005) %>%
group_by(product_code,product_name) %>%
summarise(sum_export_value = sum(export_value)) %>%
arrange(desc(sum_export_value)) %>%
head()
# Use the 'df_rca' dataframe for this
print('1995: ')
df_rca %>%
filter(region_col=='Ukraine',time_col==1995) %>%
arrange(desc(RCAcpt)) %>%
select(product_col,RCAcpt,value_col) %>%
head
print('2005: ')
df_rca %>%
filter(region_col=='Ukraine',time_col==2005) %>%
arrange(desc(RCAcpt)) %>%
select(product_col,RCAcpt,value_col) %>%
head
df_cppt %>%
filter(product_col_1=='Stainless steel wire') %>%
arrange(desc(phi)) %>%
head()
df_ps <- df_rca %>%
filter(region_col=='Ukraine', time_col==1995,RCAcpt>1,value_col > 4000000) %>%
select(product_col,value_col,product_code)
file_name <- tempfile(fileext = ".csv")
write.csv(df_ps, file=file_name,row.names=FALSE)
# Call python functions from R
source_python('https://raw.githubusercontent.com/cid-harvard/py-productspace/master/create_product_space_v2.py')
# We will use the glue library here to add R variables as Python parameters
network_image_file_name <- tempfile(fileext=".png")
string_python <- glue("create_product_space(df_plot_dataframe_filename ='{file_name}', \\\
df_plot_node_col = 'product_code', \\\
df_node_size_col = 'value_col', \\\
output_image_file ='{network_image_file_name}')"
)
py_run_string(string_python)
sprintf('product space image saved in %s',network_image_file_name)
# Plot the product space now
pp <- readPNG(network_image_file_name)
options(repr.plot.width=15, repr.plot.height=15)
grid::grid.raster(pp,width=1.8,height=1.8)
print('the network can be saved as an image locally by right clicking on it in the notebook
and clicking "Save Image", or by editing the output_image_file parameter above')
df_ps <- df_rca %>%
filter(region_col=='Ukraine', time_col==2015,RCAcpt>1,value_col > 4000000) %>%
select(product_col,value_col,product_code)
file_name <- tempfile(fileext = ".csv")
write.csv(df_ps, file=file_name,row.names=FALSE)
# Call python functions from R
source_python('https://raw.githubusercontent.com/cid-harvard/py-productspace/master/create_product_space_v2.py')
# We will use the glue library here to add R variables as Python parameters
network_image_file_name <- tempfile(fileext=".png")
string_python <- glue("create_product_space(df_plot_dataframe_filename ='{file_name}', \\\
df_plot_node_col = 'product_code', \\\
df_node_size_col = 'value_col', \\\
output_image_file ='{network_image_file_name}')"
)
py_run_string(string_python)
sprintf('product space image saved in %s',network_image_file_name)
# Plot the product space now
pp <- readPNG(network_image_file_name)
options(repr.plot.width=15, repr.plot.height=15)
grid::grid.raster(pp,width=1.8,height=1.8)
print('the network can be saved as an image locally by right clicking on it in the notebook
and clicking "Save Image", or by editing the output_image_file parameter above')
df_eci %>%
arrange(desc(eci)) %>%
head
df_eci %>%
arrange(desc(eci)) %>%
tail()
df_pci %>%
arrange(desc(pci)) %>%
head()
df_pci %>%
arrange(desc(pci)) %>%
tail()
df_eci_allyrs <- data.frame()
years <- 1995:2016
for (yeart in years) {
sprintf('doing year %s',yeart)
# Loop now
head(df_orig)
dft <- df_orig %>% filter(year==yeart) %>% select (country_name,product_name,export_value)
dft <- dft %>%
rename(country = country_name,
product = product_name,
value = export_value)
# balassa index (rca, 1 if > 1)
bi <- balassa_index(dft)
# calculate eci / pci, using reflections here: same values as py-ecomplexity package
cm <- complexity_measures(bi,method='reflections')
# convert to tibble, add country names, sort from most to least complex
# -- xci labels are set with setNames (extract with 'names')
df_eci <- cm$complexity_index_country %>%
as_tibble() %>%
mutate(country = names(cm$complexity_index_country)) %>%
rename(eci = value)
df_eci$year = yeart
head(df_eci)
df_eci_allyrs <- bind_rows(df_eci_allyrs,df_eci)
}
# plot eci over the years
dft <- filter(df_eci_allyrs,country == 'Ukraine')
dft %>% ggplot(aes(x = year, y = eci)) + geom_line()
# - keep 2015, sort by eci and create row number
dft <- df_eci_allyrs %>%
filter(year == 2015)  %>%
arrange(desc(eci)) %>%
mutate(row_number = row_number())
# countries above and below Ukraine in ranking
row_number1 <- filter(dft,country=='Ukraine')$row_number-5
row_number2 <- filter(dft,country=='Ukraine')$row_number+5
# show
dft %>% slice(row_number1:row_number2)
df_ukr <- df_rca %>%
filter(time_col == 2015,region_col=='Ukraine',RCAcpt > 1)
# to merge pci into the dataframe, add leading zero if 3-digit
df_ukr$len_product_code = str_length(df_ukr$product_code)
df_ukr <- df_ukr %>%
mutate(product_code = ifelse(len_product_code == 3, paste('0',product_code,sep=""),product_code))
# strip leading / trailing spaces
df_ukr$product_code <- trimws(df_ukr$product_code, which = c("both"))
# merge pcis from 2000 into dataframe
df_ukr <- left_join(df_ukr, df_pci, by = c("product_code" = "product_code"))
# sort
head(arrange(df_ukr,desc(pci)))
head(df_ukr,20)
# store df_ps dataframe in R's temporary folder before loading it into Python
file_name <- tempfile(fileext = ".csv")
write.csv(df_ps, file=file_name,row.names=FALSE)
# Call the python function from R
source_python('https://raw.githubusercontent.com/cid-harvard/py-productspace/master/create_product_space_v2.py')
# Filename of product space image (saved in R's temporary folder)
network_image_file_name <- tempfile(fileext=".png")
# To add R variables as Python parameters, we'll use the glue library
string_python <- glue("create_product_space(df_plot_dataframe_filename ='{file_name}', \\\
df_plot_node_col = 'product_code', \\\
df_node_size_col = 'value_col', \\\
output_image_file ='{network_image_file_name}')"
)
# Run the python string
py_run_string(string_python)
sprintf('product space image saved in %s',network_image_file_name)
# Plot the product space now
# -- load png file
pp <- readPNG(network_image_file_name)
# -- enlarge plot area in Jupyter Notebook
options(repr.plot.width=15, repr.plot.height=15)
# -- plot, enlarge width / height for higher resolution
grid::grid.raster(pp,width=1.8,height=1.8)
print('the network can be saved as an image locally by right clicking on it in the notebook
and clicking "Save Image", or by editing the output_image_file parameter above')
print('installing packages, takes some mins on Google Colab')
ptm <- proc.time()
print('installing tidyverse')
install.packages('tidyverse')
proc.time() - ptm
ptm <- proc.time()
print('installing reticulate')
install.packages('reticulate')
proc.time() - ptm
ptm <- proc.time()
print('installing foreign')
install.packages('foreign')
proc.time() - ptm
ptm <- proc.time()
print('installing png')
install.packages('png')
proc.time() - ptm
ptm <- proc.time()
print('installing economiccomplexity')
install.packages('economiccomplexity')
proc.time() - ptm
ptm <- proc.time()
print('installing tidylog')
install.packages('tidylog')
proc.time() - ptm
print('done installing packages')
#library('arrow') # for reading parquet etc.
library('foreign') # to load STATA files into R
library('glue') # to concatenate strings / variables
library('png') # to load / show image files
library(tidylog, warn.conflicts = FALSE) # for join statistics, e.g. left_only
library('economiccomplexity')
library("reticulate") # R - Python interaction
# -- if reticulate throws error on OSX, run: brew install xquartz --cask
library('repr') # to change IRkernel properties (R kernel in Jupyter Notebook)
library('tidyverse') # data analysis standard toolkit
# -- readr: for reading data
# -- ggplot2: for plotting
# -- tibble: for creating “tibbles”; these are the tidyverse’s take on data frames.
# -- dplyr: for manipulating tibbles (or data frames); creating new variables, calculating summary statistics etc.
# -- tidyr: for reshaping data (making it from long to wide format, and vice versa)
# -- purrr: for functional programming.
# -- stringr: for manipulating strings
# -- forcats: FOR CATegorical data (factors); this makes it easier to reorder and rename the levels in factor variables.
# -- library(datasets) # - Built in datasets
print('loaded libraries')
print('loading trade data - takes 1 - 3 mins')
df_orig <- read_csv('https://www.dropbox.com/s/3n4r4qo4j0jjpln/trade.csv?dl=1')
install.packages("economiccomplexity")
install.packages("tidylog")
#df_orig <- read_csv('~/Dropbox/proj/org_zhtml_projects/product-space-eci-workshop/files/trade.csv')
print('trade data loaded')
sample_n(df_orig,10) # show 10 random rows
unique(df_orig$year)
length(unique(df_orig$product_name))
STRING <- 'Netherland'
df_orig %>%
filter(grepl(STRING, country_name)) %>%
distinct(country_name)
# store df_ps dataframe in R's temporary folder before loading it into Python
file_name <- tempfile(fileext = ".csv")
write.csv(df_ps, file=file_name,row.names=FALSE)
# Call the python function from R
source_python('https://raw.githubusercontent.com/cid-harvard/py-productspace/master/create_product_space_v2.py')
