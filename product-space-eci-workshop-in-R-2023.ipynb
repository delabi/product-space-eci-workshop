{"cells":[{"cell_type":"markdown","metadata":{},"source":"Trade and patents: RCAs, proximities, product space and economic complexity in R\n================================================================================\n\n"},{"cell_type":"markdown","metadata":{},"source":["4 February 2023, Matte Hartog (matte \\_ hartog@hks.harvard.edu)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Notes\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Google colab link Python:\n\n[https://colab.research.google.com/github/matteha/product-space-eci-workshop/blob/main/product-space-eci-workshop-2022.ipynb](https://colab.research.google.com/github/matteha/product-space-eci-workshop/blob/main/product-space-eci-workshop-2022.ipynb)\n\nGoogle colab link in R:\n[https://colab.research.google.com/github/matteha/product-space-eci-workshop/blob/main/product-space-eci-workshop-in-R-2023.ipynb](https://colab.research.google.com/github/matteha/product-space-eci-workshop/blob/main/product-space-eci-workshop-in-R-2023.ipynb)\n\nTo run code in Google Colab, you need a Google account.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## To do first\n\n"]},{"cell_type":"markdown","metadata":{},"source":["In Google Colab:\n\n1.  Turn on Table of Contents: (in browser, click on &rsquo;View&rsquo; in top, then &rsquo;Table of Contents&rsquo;)\n\n2.  Expand all sections (&rsquo;View&rsquo; > &rsquo;Expand Sections&rsquo; if not greyed out)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Outline of lab session\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Google Colab gives you access to a Jupyter Notebook but with an R kernel instead of a Python kernel, see:\n\n[https://github.com/IRkernel/IRkernel](https://github.com/IRkernel/IRkernel)\n\nWe&rsquo;ll cover:\n\n-   Introduction to trade data\n\n-   Calculating RCAs, co-occurences and proximities\n    -   Product and technology proximities\n    -   Trade: specialization of countries over time\n    -   Technologies (patents): specialization of countries and US cities over time\n\n-   Using Python libraries in R: Product space visualization\n\n-   Calculating Product Complexity / Economic Complexity (by destination)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Trade data\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Background\n\n"]},{"cell_type":"markdown","metadata":{},"source":["The product space is, as well as its derivations / related measures such as economic complexity and the Growth&rsquo;s annual rankings of countries by economic complexity (at [https://atlas.cid.harvard.edu](https://atlas.cid.harvard.edu)), are based on trade data between countries.\n\nThe Growth Lab maintains and periodically updates a cleaned version of trade data at Harvard Dataverse:\n\n[https://dataverse.harvard.edu/dataverse/atlas](https://dataverse.harvard.edu/dataverse/atlas)\n\nThis dataset contains bilateral trade data among 235 countries and territories in thousands of different products categories (a description of the data can be found at: [http://atlas.cid.harvard.edu/downloads](http://atlas.cid.harvard.edu/downloads)).\n\nHow does the data look like? We will explore the data in R whilst mainly using the &rsquo;tidyverse&rsquo; packages (most popular R packages for data analysis).\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Footnote on trade and services (ICT, tourism, etc.):\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Services and tourism are included in the Growth Lab&rsquo;s Atlas and trade data as well as of September 2018. See announcement at:\n\n[https://atlas.cid.harvard.edu/announcements/2018/services-press-release](https://atlas.cid.harvard.edu/announcements/2018/services-press-release)\n\nObtained from IMF, trade in services covers four categories of economic activities between producers and consumers across borders:\n\n-   services supplied from one country to another (e.g. call centers)\n-   consumption in other countries (e.g. international tourism)\n-   firms with branches in other countries (e.g. bank branches overseas)\n-   individuals supplying services in another country (e.g. IT consultant abroad)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Install necessary R packages\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["print('installing packages, takes some mins on Google Colab')\n\nptm <- proc.time()\nprint('installing tidyverse')\ninstall.packages('tidyverse')\nproc.time() - ptm\n\nptm <- proc.time()\nprint('installing reticulate')\ninstall.packages('reticulate')\nproc.time() - ptm\n\nptm <- proc.time()\nprint('installing foreign')\ninstall.packages('foreign')\nproc.time() - ptm\n\nptm <- proc.time()\nprint('installing png')\ninstall.packages('png')\nproc.time() - ptm\n\nptm <- proc.time()\nprint('installing economiccomplexity')\ninstall.packages('economiccomplexity')\nproc.time() - ptm\n\nptm <- proc.time()\nprint('installing tidylog')\ninstall.packages('tidylog')\nproc.time() - ptm\n\nprint('done installing packages')"]},{"cell_type":"markdown","metadata":{},"source":["### Load necessary R packages\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["loaded libraries"]}],"source":["#library('arrow') # for reading parquet etc.\nlibrary('foreign') # to load STATA files into R\nlibrary('glue') # to concatenate strings / variables\nlibrary('png') # to load / show image files\nlibrary(tidylog, warn.conflicts = FALSE) # for join statistics, e.g. left_only\nlibrary('economiccomplexity')\nlibrary(\"reticulate\") # R - Python interaction\n# -- if reticulate throws error on OSX, run: brew install xquartz --cask\nlibrary('repr') # to change IRkernel properties (R kernel in Jupyter Notebook)\nlibrary('tidyverse') # data analysis standard toolkit\n# -- readr: for reading data\n# -- ggplot2: for plotting\n# -- tibble: for creating “tibbles”; these are the tidyverse’s take on data frames.\n# -- dplyr: for manipulating tibbles (or data frames); creating new variables, calculating summary statistics etc.\n# -- tidyr: for reshaping data (making it from long to wide format, and vice versa)\n# -- purrr: for functional programming.\n# -- stringr: for manipulating strings\n# -- forcats: FOR CATegorical data (factors); this makes it easier to reorder and rename the levels in factor variables.\n# -- library(datasets) # - Built in datasets\nprint('loaded libraries')"]},{"cell_type":"markdown","metadata":{},"source":["### Download trade dataset and load into memory\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Trade data is constantly updated by the Growth Lab, you can find the most recent version of the trade data at our Dataverse here:\n\n[https://dataverse.harvard.edu/dataverse/atlas](https://dataverse.harvard.edu/dataverse/atlas)\n\nBelow we&rsquo;re using the trade data using the HS classification (&rsquo;Harmonized System 1992&rsquo; - alternative is &rsquo;SITC - Standard Industrial Trade Classification&rsquo; which goes back further in time) at the 4 digit level (alternative is 2 or 6 - 6 has more detail). It can be found here:\n\n[https://dataverse.harvard.edu/file.xhtml?fileId=4946953&version=4.0](https://dataverse.harvard.edu/file.xhtml?fileId=4946953&version=4.0)\n\nThe trade file we&rsquo;re using below has a fix implemented in the labels (strings) of the products - some products currently erronuously have the same strings (e.g. product codes 5209 and 5211 in Zimbabwe have the same product string). The file is regularly updated by the Growth Lab.\n\nTo load the data directly we&rsquo;re using a Dropbox link with the fix implemented (Dataverse normally requires one to fill in an agreement form first but see Section 1 (by Shreyas) on how to use the dataverse library in R to load data from there directly into R).\n\n(The trade file is a large file because it includes country / product strings, takes 1 - 3 minutes to load. One can also merge strings in separately but for illustrative purposes it is easier to have them all preloaded - also to avoid memory problems that R quickly runs into).\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["print('loading trade data - takes 1 - 3 mins')\ndf_orig <- read_csv('https://www.dropbox.com/s/3n4r4qo4j0jjpln/trade.csv?dl=1')\n#df_orig <- read_csv('~/Dropbox/proj/org_zhtml_projects/product-space-eci-workshop/files/trade.csv')\nprint('trade data loaded')"]},{"cell_type":"markdown","metadata":{},"source":["### Exploring the trade data\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Structure of dataset\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Our $X_{cpt}$ matrix:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["sample_n(df_orig,10) # show 10 random rows"]},{"cell_type":"markdown","metadata":{},"source":["#### What years are in the data?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["unique(df_orig$year)"]},{"cell_type":"markdown","metadata":{},"source":["#### How many products are in the data?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["length(unique(df_orig$product_name))"]},{"cell_type":"markdown","metadata":{},"source":["#### Finding specific countries / products based on partial string matching\n\n"]},{"cell_type":"markdown","metadata":{},"source":["If you&rsquo;re interested in finding data on certain countries / products but not sure how exactly these are spelled in the data (or are spelled with / without e.g. capital letters).\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["STRING <- 'Netherland'\ndf_orig %>%\n  filter(grepl(STRING, country_name)) %>%\n  distinct(country_name)"]},{"cell_type":"markdown","metadata":{},"source":["You can also ignore lower/uppercase here (e.g. &rsquo;wine&rsquo; vs &rsquo;Wine&rsquo; may be relevant)\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["STRING = 'wine'\ndf_orig %>%\n  filter(grepl(STRING, product_name, ignore.case = TRUE)) %>%\n  distinct(product_name)"]},{"cell_type":"markdown","metadata":{},"source":["#### Example: What were the major export products of the USA in 2012?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_orig %>%\n  filter(country_code == 'USA' & year == 2012) %>%\n  group_by(product_code,product_name) %>%\n  summarise(sum_export_value = sum(export_value)) %>%\n  arrange(desc(sum_export_value)) %>%\n  head()"]},{"cell_type":"markdown","metadata":{},"source":["#### Example: How did exports of Cars evolve over time in the USA?\n\n"]},{"cell_type":"markdown","metadata":{},"source":["From about 10 billion USD up to almost $60 billion USD.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_orig %>%\n  filter(country_code == 'USA' & product_code == 8703) %>%\n  ggplot(aes(x = year, y = export_value)) + geom_line()"]},{"cell_type":"markdown","metadata":{},"source":["## Revealed comparative advantage (RCA)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["What products are countries specialized in? For that, following Hidalgo et al. (2007), we calculate the Revealed Comparative Advantage (RCA) of each country-product pair: how much a country &rsquo;over-exports&rsquo; a product in comparison to all other countries.\n\nTechnically this is the Balassa index of comparative advantage, calculated as follows for product $p$ and country $c$ at time $t$:\n\n\\begin{equation} \\label{e_RCA}\n{RCA}_{cpt}=\\frac{X_{cpt}/X_{ct}}{X_{pt}/X_{t}}\n\\tag{1}\n\\end{equation}\n\nwhere $X_{cpt}$ represents the total value of country $c$’s exports of product $p$ at time $t$ across all importers. An omitted subscript indicates a summation over the omitted dimension, e.g.: $X_{t}=\\sum \\limits_{c,p,t} X_{cpt}$.\n\nA product-country pair with $RCA>1$ means that the product is over-represented in the country&rsquo;s export basket.\n\nWe use the original trade dataset (&rsquo;df<sub>orig</sub>&rsquo;) that is loaded into memory, calculating RCAs as follows:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["calc_rca <- function(data,region_col,product_col,time_col,value_col) {\n    # - add all possible products for each country with export value 0\n    # - else matrices later on will have missing values in them, complicating calculations\n    df_all <- data %>%\n    expand(time_col,region_col, product_col)\n\n    # merge data back in\n    df_all <- left_join(df_all,data,by=c('time_col','region_col','product_col'))\n\n    # set export value to 0 if missing (fills in the extra combinations created)\n    df_all <- df_all %>%\n      mutate(value_col = replace_na(value_col, 0))\n\n    # define RCA properties:\n\n    # -- Xcpt\n    df_all <- df_all %>% mutate(Xcpt = value_col)\n\n    # -- Xct\n    df_all <- df_all %>%\n      group_by(time_col,region_col) %>%\n      mutate(Xct = sum(value_col))\n\n    # -- Xpt\n    df_all <- df_all %>%\n      group_by(time_col,product_col) %>%\n      mutate(Xpt = sum(value_col))\n\n    # -- Xt\n    df_all <- df_all %>%\n      group_by(time_col) %>%\n      mutate(Xt = sum(value_col))\n\n    # -- RCAcpt\n    df_all$RCAcpt = (df_all$Xcpt/df_all$Xct)/(df_all$Xpt/df_all$Xt)\n\n    # set RCAcpt to 0 if missing, e.g. if product / country have 0 (total) exports\n    df_all <- df_all %>%\n      mutate(RCAcpt = replace_na(RCAcpt, 0))\n\n    # drop the properties created above\n    df_all <- select(df_all, -c(Xcpt,Xct,Xpt,Xt))\n\n    #####\n    return(df_all)\n}"]},{"cell_type":"markdown","metadata":{},"source":["Calculate RCAs:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# rename columns accordingly\ndf_rca <- df_orig %>%\n  rename(time_col = year,\n         region_col = country_name,\n         product_col = product_name,\n         value_col = export_value)\n\n# calculate RCAs\ndf_rca <- calc_rca(data=df_rca,region_col,product_col,time_col,value_col)\n\nprint('df_rca ready')"]},{"cell_type":"markdown","metadata":{},"source":["( Sidenote: in Python you can run it as follows - without renaming columns beforehand - which may be little more intuitive:\n\ndf \\_ rca = calc \\_ rca(data=df \\_ orig,country \\_ col=&rsquo;country \\_ name&rsquo;,product \\_ col=&rsquo;product \\_ name&rsquo;,time \\_ col=&rsquo;year&rsquo;,value \\_ col=&rsquo;export \\_ value&rsquo;)\n\nbut when passing in column names from tidyverse into functions you quickly run into issues with tidyverse where non-standard evaluation (NSE) is common - symbols being evaluated in the context of the tibble / dataframe in use. Hence you&rsquo;d have to program it such as &ldquo;group \\_ by(!!sym(country \\_ col),!!sym(time \\_ col)) %>%&rdquo; which quickly becomes painful.\n\nInformative post here: [https://www.brodieg.com/2020/05/05/on-nse/> ](https://www.brodieg.com/2020/05/05/on-nse/> ))\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Sample of dataset\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["sample_n(df_rca,5)"]},{"cell_type":"markdown","metadata":{},"source":["### Example: What products are The Netherlands and Saudi Arabia specialized in, in 2000?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["print(\"\\n The Netherlands: \\n\")\n\ndf_rca %>%\n  filter(region_col=='Netherlands', time_col==2000) %>%\n  arrange(desc(RCAcpt)) %>%\n  select(product_col,RCAcpt) %>%\n  head(n=5)\n\nprint(\"\\n Saudi Arabia:\\n\")\n\ndf_rca %>%\n  filter(region_col=='Saudi Arabia', time_col==2000) %>%\n  arrange(desc(RCAcpt)) %>%\n  select(product_col,RCAcpt) %>%\n  head(n=5)"]},{"cell_type":"markdown","metadata":{},"source":["## Product proximity (based on co-occurences)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Calculating product co-occurences and proximities\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Knowing which countries are specialized in which products, the next step analyzes the extent to which two products are over-represented ($RCA>1$) in the same countries.\n\nAs noted in the lecture, the main insight supporting this inference is that countries will produce combinations of products that require similar capabilities.\n\nHence we infer capabilities from trade patterns, because the capabilities of a country is a priori hard to determine and capabilities themselves are hard to observe.\n\nHence, **the degree to which two products cooccur in the export baskets of the same countries provides an indication of how similar the capability requirements of the two products are**.\n\nWe will calculate the co-occurence matrix of products below.\n\nFirst, a product is &rsquo;present&rsquo; in a country if the country exports the product with $RCA>1$:\n\n\\begin{equation} \\label{e_presence}\nM_{cp}=\\begin{cases}\n    1 & \\text{if ${RCA}_{cp}>1$}; \\\\\n    0 & \\text{elsewhere.}\n    \\end{cases}\n\\tag{2}\n\\end{equation}\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_rca$Mcp <- 0\ndf_rca[df_rca$RCAcpt>1, 'Mcp'] <- 1"]},{"cell_type":"markdown","metadata":{},"source":["Next, we calculate how often two products are present in the same countries, using the Mcp threshold:\n\n\\begin{equation} \\label{e_cooc}\nC_{pp'}=\\sum \\limits_{c} M_{cp} M_{cp'}\n\\tag{3}\n\\end{equation}\n\nTo get an accurate value of product proximity, we need to correct these numbers for the extent to which products are present in general in trade flows between countries. To do so, Hidalgo et al. (2007) calculate product proximity as follows, defining it as the minimum of two conditional probabilities:\n\n\\begin{equation}\nC_{ppt'}  = \\min \\left( \\frac{C_{pp'}}{C_{p}},\\frac{C_{pp'}}{C_{p'}} \\right)\n\\tag{4}\n\\end{equation}\n\nThe minimum here is used to elimate a &rsquo;false positive&rsquo;.\n\nHence we correct for how prevalent specialization in product $i$ and product $j$ is across countries (i.e. the &rsquo;ubiquity&rsquo; of the products).\n\nWe will use the first year of data in the dataset, **1995,** below.\n\nNote that to reduce yearly votality, Hidalgo et al. (2007) aggregate the trade data across multiple years (1998-2000) when calculating RCAs and product proximities for the product space. (However, when comparing the product space across years, they do use individual years).\n\nFunction to calculate cppt:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["calc_cppt <- function(data,region_col,product_col) {\n\n  # create product_col_2 column (to create all combinations of products within columns)\n  data$product_col_1 <- data$product_col\n  data$product_col_2 <- data$product_col_1\n\n  # create all product combinations within countries\n  print('creating combinations')\n  dft3 <- data %>% group_by(region_col) %>% complete(product_col_1, product_col_2)\n  print('combinations ready')\n\n  # drop diagonal\n  dft3 <- filter(dft3,product_col_1!=product_col_2)\n\n  # calculate N of times that {product_col}s occur together\n  dft3$count = 1\n  dft3 <- dft3 %>%\n    group_by(product_col_1,product_col_2) %>%\n    summarise(Cpp = sum(count))\n\n  # calculate ubiquity\n  df_ub <- data %>%\n    group_by(product_col) %>%\n    summarize(Mcp = sum(Mcp))\n\n  # Merge ubiquities of product 1 and 2 into cpp matrix\n  df_ub <- df_ub %>%\n    rename(product_col_1 = product_col)\n  dft3 <- left_join(dft3,df_ub,by=c('product_col_1'))\n\n  df_ub <- df_ub %>%\n    rename(product_col_2 = product_col_1)\n  dft3 <- left_join(dft3,df_ub,by=c('product_col_2'))\n\n  # Take minimum of conditional probabilities\n  dft3$kpi = dft3$Cpp/dft3$Mcp.x\n  dft3$kpj = dft3$Cpp/dft3$Mcp.y\n  dft3$phi = dft3$kpi\n  dft3 <- dft3 %>%\n      mutate(phi = ifelse(kpj < kpi, kpj ,kpi))\n\n  ############\n  return(dft3)\n}"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# keep only year 1995 and only country-product combinations where Mcp == 1 (thus RCAcpt > 1)\ndft <- filter(df_rca,time_col==1995,Mcp==1)\n# calculate cppt\ndf_cppt <- calc_cppt(data=dft,region_col,product_col)\n\nprint('cppt product co-occurences and proximities dataframe ready')"]},{"cell_type":"markdown","metadata":{},"source":["#### Products that co-occur most often\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_cppt %>%\n  arrange(desc(Cpp)) %>%\n  head(n=10)"]},{"cell_type":"markdown","metadata":{},"source":["#### Most proximate products\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_cppt %>%\n  arrange(desc(phi)) %>%\n  head(n=10)"]},{"cell_type":"markdown","metadata":{},"source":["## Patents: Country and city specializations over time, and technology proximities\n\n"]},{"cell_type":"markdown","metadata":{},"source":["We can apply this to patent data as well.\n\nAt the Growth Lab we have access to and worked with the Patstat database, patents from Google Bigquery, patents from PatentView, HistPat, and patents obtained from USPTO publications from 1790 onwards through optical character recognition.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Technological diversification of countries\n\n"]},{"cell_type":"markdown","metadata":{},"source":["First we look at diversification of countries, using patents extracted from the Patstat database.\n\nPatstat includes all patents from ~ 1903 onwards.\n\nBelow is an outline of what is available in Patstat:\n\n![img](https://www.dropbox.com/s/zqgv7fi61c2ip2f/patstat.png?dl=1)\n\nBelow we use an aggregated file created from the Patstat database, containing:\n\n-   Year\n-   Country\n-   Technology class\n-   Count (N of patents)\n\nwhich I put on Dropbox temporarily so we can load it in directly into Google CoLab.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Load patent data\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["print('loading patent data')\n# load STATA file into R directly from URL (using the 'foreign' library)\ndfp <- read.dta('https://www.dropbox.com/s/nwox3dznoupzm0q/patstat_year_country_tech_inventor_locations.dta?dl=1')\n#dfp <- read.dta('~/Dropbox/proj/org_zhtml_projects/product-space-eci-workshop/files/patstat_year_country_tech/patstat_year_country_tech_inventor_locations.dta')\nprint('patent data loaded')"]},{"cell_type":"markdown","metadata":{},"source":["##### Sample of data\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["sample_n(dfp,10)"]},{"cell_type":"markdown","metadata":{},"source":["##### What are the first and last years in the data?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["min(dfp$year)\nmax(dfp$year)"]},{"cell_type":"markdown","metadata":{},"source":["##### How many countries and technology classes are in the data?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["print('Unique N of counties:')\n\nlength(unique(dfp$country_name))\n\nprint('Unique N of technologies:')\n\nlength(unique(dfp$tech))"]},{"cell_type":"markdown","metadata":{},"source":["#### RCAs\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# rename columns accordingly\ndfp_rca <- dfp %>%\n  rename(time_col = year,\n         region_col = country_name,\n         product_col = tech,\n         value_col = count)\n\n# calculate RCA\ndfp_rca <- calc_rca(data=dfp_rca,region_col,product_col,time_col,value_col)\n\nprint('patent rcas ready')"]},{"cell_type":"markdown","metadata":{},"source":["##### What were Japan and Germany specialized in, in 1960 and 2010?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["countries <- list(\"Japan\", \"Germany\")\nyears <- list(1960, 2010)\nfor (country in countries) {\n  for (year in years) {\n    dft <- dfp_rca %>%\n      filter(region_col == country, time_col == year) %>%\n      arrange(desc(RCAcpt)) %>%\n      head\n    print(dft)\n  }\n}"]},{"cell_type":"markdown","metadata":{},"source":["#### Technology proximities\n\n"]},{"cell_type":"markdown","metadata":{},"source":["What technology classes are most proximate (in 2010)?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Define Mcp\ndfp_rca$Mcp = 0\ndfp_rca <- dfp_rca %>%\n  mutate(Mcp = ifelse(RCAcpt> 1, 1,0))\n\n# Keep only years 2010 and only country-product combinations where Mcp == 1 (thus RCAcp > 1)\ndft <-  dfp_rca %>%\n  filter(time_col==2010,Mcp==1)\n\n# Calculate cppt\ndfp_cppt <- calc_cppt(data=dft,region_col,product_col)\n\nprint('cppt patent co-occurences and proximities dataframe ready')\n\n# Show most proximate technologies\ndfp_cppt %>%\n  arrange(desc(phi)) %>%\n  head(10)"]},{"cell_type":"markdown","metadata":{},"source":["(You can use density regressions as well here to predict technological diversification of countries. Shreyas will cover this in a later Review Session).\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Technological diversification of cities in the USA\n\n"]},{"cell_type":"markdown","metadata":{},"source":["We can also investigate technological diversification at the sub-national level.\n\nBelow we&rsquo;re using patent counts per city per technology from 1975 onwards (obtained from patents extracted from the PatentView database). Patents&rsquo; technologies are defined according to the Cooperative Patent Classification (CPC).\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Load patent data\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# load csv file into R directly from URL\nprint('loading patent data')\ndfp <- read.csv('https://www.dropbox.com/s/th4zqkmuofmg4u3/patentview_class_2022.csv?dl=1')\n#dfp <- read.csv('~/Dropbox/proj/odyssey_from/patentview_class_2022.csv')\nprint('patent data loaded')"]},{"cell_type":"markdown","metadata":{},"source":["##### Sample of data\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["sample_n(dfp,10)"]},{"cell_type":"markdown","metadata":{},"source":["##### What are the first and last years in the data?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["min(dfp$year)\nmax(dfp$year)"]},{"cell_type":"markdown","metadata":{},"source":["##### How many cities (regions) and technology classes are in the data?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["print('Unique N of counties:')\nlength(unique(dfp$region))\n\nprint('Unique N of technologies:')\nlength(unique(dfp$tech))"]},{"cell_type":"markdown","metadata":{},"source":["#### RCAs\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# rename columns accordingly\ndfp_rca <- dfp %>%\n  rename(time_col = year,\n         region_col = region,\n         product_col = tech,\n         value_col = count)\n\n# calculate RCA\n# -- keep 1980 and 2017\ndfp_rca <- dfp_rca %>% filter(time_col==1980 | time_col == 2017)\n\n# -- calculate\ndfp_rca <- calc_rca(data=dfp_rca,region_col,product_col,time_col,value_col)\n\nprint('patent rcas ready')"]},{"cell_type":"markdown","metadata":{},"source":["##### What were Silicon Valley (Santa Clara county) and Detroit (MI - Wayne county) specialized in, in 1980 and 2017?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# -- minimal 5 patents\n#regions <- list(\"CA > Santa Clara\", \"MI > Wayne\")\nregions <- list('CA > Santa Clara > San Jose','MI > Wayne > Detroit')\nyears <- list(1980, 2017)\nfor (region in regions) {\n  for (year in years) {\n    dft <- dfp_rca %>%\n      filter(grepl(region, region_col),time_col==year,value_col>5) %>%\n      arrange(desc(RCAcpt)) %>%\n      head\n    print(dft)\n  }\n}"]},{"cell_type":"markdown","metadata":{},"source":["#### Technology proximities (cpc)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["What technology classes (cpc classification) are most proximate (in 2010)?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Define Mcp\ndfp_rca$Mcp = 0\ndfp_rca <- dfp_rca %>%\n  mutate(Mcp = ifelse(RCAcpt> 1, 1,0))\n\n# Keep only years 2010 and only country-product combinations where Mcp == 1 (thus RCAcp > 1)\ndft <-  dfp_rca %>%\n  filter(time_col==2017,Mcp==1)\n\n# Calculate cppt\ndfp_cppt <- calc_cppt(data=dft,region_col,product_col)\n\nprint('df_cppt ready')\nprint('cppt patent co-occurences and proximities dataframe ready')\n\n# Show most proximate technologies\ndfp_cppt %>%\n  arrange(desc(phi)) %>%\n  head(10)"]},{"cell_type":"markdown","metadata":{},"source":["## Product space\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Overview\n\n"]},{"cell_type":"markdown","metadata":{},"source":["We now have a measure of similarity between products (and patents), which is the core of the product space.\n\n[https://atlas.cid.harvard.edu/explore/network?country=114&year=2018&productClass=HS&product=undefined&startYear=undefined&target=Product&partner=undefined](https://atlas.cid.harvard.edu/explore/network?country=114&year=2018&productClass=HS&product=undefined&startYear=undefined&target=Product&partner=undefined)\n\n![img](/Users/admin/Dropbox/proj/org_zhtml_projects/product-space-eci-workshop/imgs/product_space_atlas_website.png)\n\n![img](https://www.dropbox.com/s/izag1xf28yldanf/product_space_atlas_website.png?dl=1)\n\nBelow we will explore the product space using R whilst interacting with Python. You can then directly manipulate the product space and visualize selectively if not possible in the Atlas interface (e.g. only products exported to certain countries).\n\nThe Github repo for this is available at [https://github.com/matteha/py-productspace](https://github.com/matteha/py-productspace).\n\nWhat we need is information on:\n\n-   Edges (ties) between nodes\n    \n    Ties between nodes represent the product proximity calculated above. Each product pair has a proximity value, but visualizing all ties, however, would result in a major &ldquo;hairball&rdquo;.\n    \n    To determine which of the ties to visualize in the product space, a &rsquo;maximum spanning tree algorithm&rsquo; is used (to make sure all nodes are connected directly or indirectly) in conjunction with a certain proximity threshold (0.55 minimum conditional probability). The details can be found in the Supplementary Material of Hidalgo et al. (2007) at [https://science.sciencemag.org/content/suppl/2007/07/26/317.5837.482.DC1](https://science.sciencemag.org/content/suppl/2007/07/26/317.5837.482.DC1).\n    \n    The data on the ties of nodes is available in the Atlas data repository at:\n    [https://dataverse.harvard.edu/file.xhtml?persistentId=doi:10.7910/DVN/FCDZBN/QSEETD&version=1.1](https://dataverse.harvard.edu/file.xhtml?persistentId=doi:10.7910/DVN/FCDZBN/QSEETD&version=1.1)\n    \n    We can directly load it into R using the link below (temporarily for this session, when using Harvard&rsquo;s dataverse you&rsquo;d need to sign a short User Agreement form so you can&rsquo;t load data directly from a URL):\n    \n    [https://www.dropbox.com/s/r601tjoulq1denf/network_hs92_4digit.json?dl=1](https://www.dropbox.com/s/r601tjoulq1denf/network_hs92_4digit.json?dl=1)\n\n-   Position of nodes\n    -   Each node is a product\n    \n    -   To position them in the product space, Hidalgo et al. (2007) used a spring embedding algorithm (which positions the nodes in such a way that there are as few crossing ties as possible, using physical simulations with force-directed algorithms), followed by hand-crafting the outcome to further visually separate distinct &rsquo;clusters&rsquo; of products.\n        \n        The data on the position of nodes (x, y coordinates) is in the same file as the one above with the data on ties (network<sub>hs92</sub><sub>4digit.json</sub>).\n        \n        We will use this fixed layout for now (James and Yang will deal with different ways to visualize multi-dimensional data in 2D/3D, e.g. with machine learning, UMAP).\n\n-   Size of nodes\n    \n    The size in the product space represents the total $ in world trade, but one can also use other attributes of nodes (e.g. if nodes are industries, the size could be total employment).\n\n-   Color of nodes\n    \n    In the product space the node color represents major product groups (e.g. Agriculture, Chemicals) following the Leamer classification. The node coloring data is available in the Atlas data repository at:\n    [https://dataverse.harvard.edu/dataverse/atlas?q=&types=files&sort=dateSort&order=desc&page=1](https://dataverse.harvard.edu/dataverse/atlas?q=&types=files&sort=dateSort&order=desc&page=1)\n    \n    We can directly load it into R using the link below (again, temporary for this session):\n    \n    [https://www.dropbox.com/s/rlm8hu4pq0nkg63/hs4_hex_colors_intl_atlas.csv?dl=1](https://www.dropbox.com/s/rlm8hu4pq0nkg63/hs4_hex_colors_intl_atlas.csv?dl=1)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### (Visualizing in the product space, using R with Python)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Some (most) tools at the Growth Lab are written in Python / STATA rather than R, but with the &rsquo;reticulate&rsquo; package in R one can interact directly with Python libraries in the backend. Below is a showcase of one way to do so;\n\nYang&rsquo;s session (Session 3) will go much deeper into visualization as such using UMAP, machine learning etc.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Prepare dataframe\n\n"]},{"cell_type":"markdown","metadata":{},"source":["First we select the country which product portfolio we wish to visualize. We&rsquo;ll use Saudi Arabia below for the dataframe of the product space (&rsquo;df<sub>ps</sub>&rsquo;).\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["COUNTRY_STRING <- 'Saudi Arabia'\ndf_ps <- df_rca %>%\n  filter(region_col==COUNTRY_STRING)\n\n# Cross-check\nif (dim(df_ps)[1]==0) {\n    print('Country string set above does not exist in data, typed correctly?')\n    STOP\n}"]},{"cell_type":"markdown","metadata":{},"source":["##### Country, RCA, year, export value selections\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Next we define what trade properties of Saudi Arabia we want to visualize. The example below visualizes specialiation in 2005 (year=2005, RCAcpt>1) of only those products with at least 40 million in trade value.\n\nThis data preparation happens before inputting into it the product space function so you can inspect the dataframe before plotting.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_ps <- df_rca %>%\n  filter(region_col==COUNTRY_STRING, time_col==2005,RCAcpt>1,value_col > 4000000) %>%\n  select(product_col,value_col,product_code)"]},{"cell_type":"markdown","metadata":{},"source":["To visualize the data in the product space, we will now use a Product Space visualization package by the Growth Lab written in Python (work in progress) at\n\n[https://github.com/cid-harvard/py-productspace](https://github.com/cid-harvard/py-productspace)\n\nThe &rsquo;reticulate&rsquo; library in R allows one to (easily) incorporate python libraries in R:\n\n[https://rstudio.github.io/reticulate/](https://rstudio.github.io/reticulate/)\n\nAny Python module can be imported into and called from R (using &rsquo;import&rsquo;). For instance, we can import Python&rsquo;s os module and call the getcwd function to show the current working directory:\n\n(in Colab this doesn&rsquo;t work anymore, see related open issue:\n[https://github.com/rstudio/reticulate/issues/1190](https://github.com/rstudio/reticulate/issues/1190)\n)\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["os <- import(\"os\")\nos$getcwd()"]},{"cell_type":"markdown","metadata":{},"source":["Below we&rsquo;ll import into R the product space visualization library in Python and visualize Saudi Arabia&rsquo;s portfolio accordingly:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# store df_ps dataframe in R's temporary folder before loading it into Python\nfile_name <- tempfile(fileext = \".csv\")\nwrite.csv(df_ps, file=file_name,row.names=FALSE)\n\n# Call the python function from R\nsource_python('https://raw.githubusercontent.com/cid-harvard/py-productspace/master/create_product_space_v2.py')\n\n# Filename of product space image (saved in R's temporary folder)\nnetwork_image_file_name <- tempfile(fileext=\".png\")\n\n# To add R variables as Python parameters, we'll use the glue library\nstring_python <- glue(\"create_product_space(df_plot_dataframe_filename ='{file_name}', \\\\\\\n                     df_plot_node_col = 'product_code', \\\\\\\n                     df_node_size_col = 'value_col', \\\\\\\n                     output_image_file ='{network_image_file_name}')\"\n                     )\n\n# Run the python string\npy_run_string(string_python)\n\nsprintf('product space image saved in %s',network_image_file_name)\n\n# Plot the product space now\n\n# -- load png file\npp <- readPNG(network_image_file_name)\n\n# -- enlarge plot area in Jupyter Notebook\noptions(repr.plot.width=15, repr.plot.height=15)\n\n# -- plot, enlarge width / height for higher resolution\ngrid::grid.raster(pp,width=1.8,height=1.8)\n\n# can also show it using ImageMagick\ninstall.packages('magick')\nimg <- magick::image_read(network_image_file_name)\nplot(img) # or print(img)\n\nprint('the network can be saved as an image locally by right clicking on it in the notebook\nand clicking \"Save Image\", or by editing the output_image_file parameter above')"]},{"cell_type":"markdown","metadata":{},"source":["Product space image:\n\n![img](https://www.dropbox.com/s/t1w6icpqd4w9wcp/product_space_v2.png?dl=1)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## -----------&#x2013;&#x2014; Break: Excercise 1 ------------------\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### What product does Ukraine export most in 1995? (excluding services such as &rsquo;transport&rsquo;, &rsquo;ict&rsquo; etc)\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["### What products is Ukraine specialized in in 1995 and 2005 and how much do they export of these?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["### Which product is most related to the product &rsquo;Stainless steel wire&rsquo;?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["### ( Plot Ukraine in the product space in 1995.)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["How would you characterize Ukraine&rsquo;s position in the product space?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["### ( Plot Ukraine in the product space in 2015.)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Do you notice a difference with 1995?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["### ( Plot your own country across different years in the product space. Do the results make sense? Do you notice any patterns?)\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["## Predicting diversification of countries: densities / density regressions\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Shreyas will cover this.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Calculating Economic Complexity / Product Complexity\n\n"]},{"cell_type":"markdown","metadata":{},"source":["We know from the product space and density regressions how products are related to one another and how that matters for diversification of countries.\n\nThe next step is to look at which parts of the product space are most interesting to ultimately reach / diversify into. Generally complex products are located in the center of the product space, and countries with a higher economic complexity tend to have higher economic growth.\n\n![img](imgs/complex_products_in_product_space.png)\n\n![img](https://www.dropbox.com/s/a231jw76yocjkkr/complex_products_in_product_space.png?dl=1)\n\nRecall from the lecture that the economic complexity index (ECI) and product complexity index (PCI) measures are derived from an iterative method of reflections algorithm on country diversity and product ubiquity (Hidalgo Hausmann 2009), or finding the eigenvalues of a country-product matrix (Mealy et al. 2019):\n\n![img](/Users/admin/Dropbox/proj/org_zhtml_projects/product-space-eci-workshop/imgs/countries_products_eci.png)\n\n![img](https://www.dropbox.com/s/dte4vwgk4tvj3rd/countries_products_eci.png?dl=1)\n\nThe STATA package to calculate this - by Sebastian Bustos and Muhammed Yildirim - is available at:\n\n[https://github.com/cid-harvard/ecomplexity](https://github.com/cid-harvard/ecomplexity)\n\nThe Python package to calculate this - by Shreyas Gadgin Matha - is available at:\n\n[https://github.com/cid-harvard/py-ecomplexity](https://github.com/cid-harvard/py-ecomplexity)\n\nThe R package to calculate this, by Mauricio Vargas, Carlo Bottai, Diego Kozlowski, Nico Pintar, The World Bank, Open Trade Statistics, is available at:\n\n[https://cran.r-project.org/web/packages/economiccomplexity/index.html](https://cran.r-project.org/web/packages/economiccomplexity/index.html)\n\n(When using other software, e.g. Excel without having access to these packages, one can also calculate ECI by directly downloading the PCI value for every product from the Atlas Dataverse repository - the ECI of a country is the mean of the PCI values of the products it has a comparative advantage in).\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Using the &rsquo;economiccomplexity&rsquo; R package\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Trade data\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# select only year 2000\ndft <- df_orig %>% filter(year==2000) %>% select (country_name,product_name,export_value)\n\n# rename columns accordingly\ndft <- dft %>%\n  rename(country = country_name,\n         product = product_name,\n         value = export_value)\n\n# calculate the Balassa index (rca, 1 if > 1)\nbi <- balassa_index(dft)\n\n# calculate eci / pci, using reflections here: same values as py-ecomplexity package\ncm <- complexity_measures(bi,method='reflections')\n\n# convert to tibble, add country names, sort from most to least complex\n# -- xci labels are set with setNames (extract with 'names')\ndf_eci <- cm$complexity_index_country %>%\n  as_tibble() %>%\n  mutate(country = names(cm$complexity_index_country)) %>%\n  rename(eci = value)\n\n# same procedure for products (pci)\ndf_pci <- cm$complexity_index_product %>%\n  as_tibble() %>%\n  mutate(product = names(cm$complexity_index_product)) %>%\n  rename(pci= value)\n\n# add product codes as well to df_pci\ndf_product_codes <- df_orig %>%\n  select(product_name,product_code) %>%\n  distinct(product_name, .keep_all= TRUE) # drop_duplicates in pandas\n\ndf_pci <- left_join(df_pci,df_product_codes,by=c('product'='product_name'))\n#########\n\nprint('eci, pci dataframes ready')"]},{"cell_type":"markdown","metadata":{},"source":["Most complex countries:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_eci %>% arrange(desc(eci)) %>% head"]},{"cell_type":"markdown","metadata":{},"source":["Most complex products:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_pci %>% arrange(desc(pci)) %>% head"]},{"cell_type":"markdown","metadata":{},"source":["### Complexity weighted by destination (example: Ukraine)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["You can also calculate economic complexity by destination.\n\nWe did this to explore opportunities for Ukraine (to connect to European value chains):\n\n[https://growthlab.cid.harvard.edu/publications/assessing-ukraines-role-european-value-chains-gravity-equation-cum-economic](https://growthlab.cid.harvard.edu/publications/assessing-ukraines-role-european-value-chains-gravity-equation-cum-economic)\n\n(Using the ECI by destination we found that highly complex products from Ukraine in the 2000s were typically destined for the Russian market, which was also one of the largest importers of products from Ukraine. The detoriation in relations with Russia led to a significant decline in exports there from 2011 onwards, resulting in Ukraine suffering from not only a quantitative but also a qualitative decline in exports).\n\nHidalgo and Hausmann (2009) calculate complexity of country $c$ as the average PCI of all products for which ${RCA}_{cp}>1$.\n\nBelow we define it as the weighted average PCI, where weights are given by the value of country $c$’s exports in each product. This allows us to define an ECI for separate export markets.\n\nLet $\\mathcal{M}$ be the set of countries that together constitute an export market (say, the EU&rsquo;s Single Market). Now, the destination-market specific ECI for country $c$ is defined as:\n\n\\begin{equation} \\label{e_ECI}\nECI_{c}^{\\mathcal{M}}=\\sum \\limits_{p} \\frac{\\sum \\limits_{d \\in \\mathcal{M}} X^{d}_{op}}{\\sum \\limits_{d \\in \\mathcal{M}} X^{d}_{o}} {PCI}_{p}   \n\\end{equation}\n\nwhere $X_{op}^{d}$ represents the exports of product $p$ from exporter $o$ to importer $d$ and an omitted subscript indicates the summation over the omitted category: $X_{o}^{d}=\\sum \\limits_{p} X_{op}^{d}$.\n\nTo calculate this, we need a dataset that has country exports **per destination** for this, which is available in the Growth Lab&rsquo;s DataVerse as:\n\n    \"country_partner_hsproduct4digit_years_2000_2016.csv\"\n\nAs this file above is 16 gigabytes, we will load a version of it for only Ukraine&rsquo;s exports. This file has been processed outside of Google colab using the code below:\n\n    df = pd.read_csv('country_partner_hsproduct4digit_years_2000_2016.csv')\n    df = df[df['location_code_code']=='UKR')\n    df = df[df['export_value']>0]\n    df.to_csv('ukr_exports_per_destination.csv',index=False)\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Complexity by destination\nprint('loading data')\n#df_ukr <- read_csv(file='~/Dropbox/proj/org_zhtml_projects/product-space-eci-workshop/files/ukr_exports_per_destination.csv')\ndf_ukr <- read_csv(file='https://www.dropbox.com/s/megm8qzn3jcwnqz/ukr_exports_per_destination.csv?dl=1')\nprint('loaded')\n\n# show sample of dataset\nsample_n(df_ukr,10)"]},{"cell_type":"markdown","metadata":{},"source":["Merge PCI from products in 2000 into the dataframe (from df<sub>ec</sub> created in previous section using py-ecomplexity).\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# add leading zero if 3-digit\ndf_ukr$len_hs_product_code = str_length(df_ukr$hs_product_code)\ndf_ukr <- df_ukr %>%\n    mutate(hs_product_code = ifelse(len_hs_product_code == 3, paste('0',hs_product_code,sep=\"\"),hs_product_code))\n\n# strip leading / trailing spaces\ndf_ukr$hs_product_code <- trimws(df_ukr$hs_product_code, which = c(\"both\"))\n\n# merge\ndf_ukr <- left_join(df_ukr, df_pci, by = c(\"hs_product_code\" = \"product_code\"))"]},{"cell_type":"markdown","metadata":{},"source":["Now we calculate the ECI by destination:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["calc_ecimc <- function(data,origin_col,destination_col,product_col,value_col,pci_col) {\n           dft <- data\n\n           # total exports by exporter-importer\n           dft <- dft %>%\n             group_by(origin_col,destination_col) %>%\n             mutate(export_value_cot = sum(value_col))\n\n           # sum of pci per export\n           dft$pci_x_export = dft$pci_col * dft$value_col\n\n           dft <- dft %>%\n             group_by(origin_col,destination_col) %>%\n             mutate(pci_x_export_sum = sum(pci_x_export))\n\n           dft$eciMc = dft$pci_x_export_sum / dft$export_value_cot\n\n           dft <- dft %>%\n             distinct(origin_col,destination_col, .keep_all= TRUE)\n\n           dft <- dft %>% select(origin_col,destination_col,eciMc)\n\n           return(dft)\n         }\n\nprint('ecimc function defined')"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_ukr_ecimc <- df_ukr %>%\n  rename(origin_col = location_code,\n         destination_col = partner_code,\n         product_col = hs_product_code,\n         value_col = export_value,\n         pci_col = pci\n  )\n\n# calculate ecimc\ndf_ukr_ecimc <- calc_ecimc(data=df_ukr_ecimc,origin_col,destination_col,product_col,value_col,pci_col)\n\nprint('dataset eci weighted ready, sample below')\n\nhead(df_ukr_ecimc)"]},{"cell_type":"markdown","metadata":{},"source":["Economic complexity of Ukrainian exports by destination: most complex highlighted (run this outside Google Colab)\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["print ('need to install highcharter / maps but takes some time on google co-lab, hence not done at beginning')\n\n###################\n###################\nptm <- proc.time()\nprint('installing highcharter')\ninstall.packages('highcharter',verbose=TRUE)\ninstall.packages('highcharter') # slow install (in colab)\nproc.time() - ptm\n\nptm <- proc.time()\nprint('installing maps')\ninstall.packages('maps',verbose=TRUE)\ninstall.packages('maps')\nproc.time() - ptm\n###################\n###################\n\nlibrary('highcharter')\nlibrary('maps')"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_ukr_ecimc_map <- df_ukr_ecimc %>%\n  rename(\"iso-a3\"=\"destination_col\")\n\nhcmap(\n  map = \"custom/world-highres3\", # high resolution world map\n  # eci in 85th percentile\n  data = filter(df_ukr_ecimc_map,eciMc>quantile(df_ukr_ecimc_map$eciMc,probs=c(0.85),na.rm=TRUE)),\n  joinBy = \"iso-a3\",\n  value = \"eciMc\",\n  showInLegend = FALSE, # hide legend\n  #nullColor = \"#DADADA\",\n  download_map_data = TRUE\n) %>% hc_colorAxis(minColor = \"orange\", maxColor = \"red\")"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["head(df_ukr_ecimc)"]},{"cell_type":"markdown","metadata":{},"source":["Map: weighted ECI of Ukrainian exports:\n\n![img](https://www.dropbox.com/s/dgotrds24lf2g5h/weighted_eci_ukraine.png?dl=1)\n\nHighly complex products are typically destined for the Russian market, which is also one of the largest importers of products from Ukraine.\n\nThe detoriation in relations with Russia led to a significant decline in exports there from 2011 onwards:\n![img](https://www.dropbox.com/s/xfl3gig3zxer0fm/total_exports_Ukraine_over_years.png?dl=1)\n\nAs a result, Ukraine suffers from not only a quantitative but also a qualitative decline in exports. In the paper we explore new opportunities for Ukraine.\n\n(Note: double-check political controversies when using mapping libraries in R / Python (e.g. geopandas, highcharter)!)\n\n![img](https://www.dropbox.com/s/twtl8p5ksgfezm0/map_ukraine.png?dl=1)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## -----------&#x2013;&#x2014; Break: Excercise 2 ------------------\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### What are countries with high complexity in 2015?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["### Vice versa, what are countries with low complexity in 2015?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["### What are products (PCI) with high complexity in 2015?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["### Vice versa, what are products (PCI) with low complexity in 2015?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["### Ukraine\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### How did Ukraine&rsquo;s economic complexity evolve over time?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["#### How does Ukraine&rsquo;s economic complexity in 2015 compare to other countries? Which countries have comparable economic complexity?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["#### What are the most complex products that Ukraine exported in 2015?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["## ---\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## ---\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## ---\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Excercise answers\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Excercise 1\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### What product does Ukraine export most in 1995? (excluding services such as &rsquo;transport&rsquo;, &rsquo;ict&rsquo; etc)\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_orig %>%\n  filter(country_name=='Ukraine',year==2005) %>%\n  group_by(product_code,product_name) %>%\n  summarise(sum_export_value = sum(export_value)) %>%\n  arrange(desc(sum_export_value)) %>%\n  head()"]},{"cell_type":"markdown","metadata":{},"source":["#### What products is Ukraine specialized in in 1995 and 2005 and how much do they export of these?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Use the 'df_rca' dataframe for this\nprint('1995: ')\ndf_rca %>%\n  filter(region_col=='Ukraine',time_col==1995) %>%\n  arrange(desc(RCAcpt)) %>%\n  select(product_col,RCAcpt,value_col) %>%\n  head\n\nprint('2005: ')\ndf_rca %>%\n  filter(region_col=='Ukraine',time_col==2005) %>%\n  arrange(desc(RCAcpt)) %>%\n  select(product_col,RCAcpt,value_col) %>%\n  head"]},{"cell_type":"markdown","metadata":{},"source":["#### Which product is most related to the product &rsquo;Stainless steel wire&rsquo;?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_cppt %>%\n  filter(product_col_1=='Stainless steel wire') %>%\n  arrange(desc(phi)) %>%\n  head()"]},{"cell_type":"markdown","metadata":{},"source":["#### Plot Ukraine in the product space in 1995.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["How would you characterize Ukraine&rsquo;s position in the product space?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_ps <- df_rca %>%\n  filter(region_col=='Ukraine', time_col==1995,RCAcpt>1,value_col > 4000000) %>%\n  select(product_col,value_col,product_code)\n\nfile_name <- tempfile(fileext = \".csv\")\nwrite.csv(df_ps, file=file_name,row.names=FALSE)\n\n# Call python functions from R\nsource_python('https://raw.githubusercontent.com/cid-harvard/py-productspace/master/create_product_space_v2.py')\n\n# We will use the glue library here to add R variables as Python parameters\nnetwork_image_file_name <- tempfile(fileext=\".png\")\n\nstring_python <- glue(\"create_product_space(df_plot_dataframe_filename ='{file_name}', \\\\\\\n                     df_plot_node_col = 'product_code', \\\\\\\n                     df_node_size_col = 'value_col', \\\\\\\n                     output_image_file ='{network_image_file_name}')\"\n                     )\n\npy_run_string(string_python)\n\nsprintf('product space image saved in %s',network_image_file_name)\n\n# Plot the product space now\npp <- readPNG(network_image_file_name)\noptions(repr.plot.width=15, repr.plot.height=15)\ngrid::grid.raster(pp,width=1.8,height=1.8)\n\nprint('the network can be saved as an image locally by right clicking on it in the notebook\nand clicking \"Save Image\", or by editing the output_image_file parameter above')"]},{"cell_type":"markdown","metadata":{},"source":["#### Plot Ukraine in the product space in 2015.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Do you notice a difference with 1995?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_ps <- df_rca %>%\n  filter(region_col=='Ukraine', time_col==2015,RCAcpt>1,value_col > 4000000) %>%\n  select(product_col,value_col,product_code)\n\nfile_name <- tempfile(fileext = \".csv\")\nwrite.csv(df_ps, file=file_name,row.names=FALSE)\n\n# Call python functions from R\nsource_python('https://raw.githubusercontent.com/cid-harvard/py-productspace/master/create_product_space_v2.py')\n\n# We will use the glue library here to add R variables as Python parameters\nnetwork_image_file_name <- tempfile(fileext=\".png\")\n\nstring_python <- glue(\"create_product_space(df_plot_dataframe_filename ='{file_name}', \\\\\\\n                     df_plot_node_col = 'product_code', \\\\\\\n                     df_node_size_col = 'value_col', \\\\\\\n                     output_image_file ='{network_image_file_name}')\"\n                     )\n\npy_run_string(string_python)\n\nsprintf('product space image saved in %s',network_image_file_name)\n\n# Plot the product space now\npp <- readPNG(network_image_file_name)\noptions(repr.plot.width=15, repr.plot.height=15)\ngrid::grid.raster(pp,width=1.8,height=1.8)\n\nprint('the network can be saved as an image locally by right clicking on it in the notebook\nand clicking \"Save Image\", or by editing the output_image_file parameter above')"]},{"cell_type":"markdown","metadata":{},"source":["#### Plot your own country across different years in the product space. Do the results make sense? Do you notice any patterns?\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Excercise 2:\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### What are countries with high complexity in 2015?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_eci %>%\n  arrange(desc(eci)) %>%\n  head"]},{"cell_type":"markdown","metadata":{},"source":["#### Vice versa, what are countries with low complexity in 2015?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_eci %>%\n  arrange(desc(eci)) %>%\n  tail()"]},{"cell_type":"markdown","metadata":{},"source":["#### What are products (PCI) with high complexity in 2015?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_pci %>%\n  arrange(desc(pci)) %>%\n  head()"]},{"cell_type":"markdown","metadata":{},"source":["#### Vice versa, what are products (PCI) with low complexity in 2015?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_pci %>%\n  arrange(desc(pci)) %>%\n  tail()"]},{"cell_type":"markdown","metadata":{},"source":["#### Ukraine\n\n"]},{"cell_type":"markdown","metadata":{},"source":["##### How did Ukraine&rsquo;s economic complexity evolve over time?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_eci_allyrs <- data.frame()\nyears <- 1995:2016\n  for (yeart in years) {\n    sprintf('doing year %s',yeart)\n    # Loop now\n    head(df_orig)\n    dft <- df_orig %>% filter(year==yeart) %>% select (country_name,product_name,export_value)\n    dft <- dft %>%\n      rename(country = country_name,\n             product = product_name,\n             value = export_value)\n    # balassa index (rca, 1 if > 1)\n    bi <- balassa_index(dft)\n    # calculate eci / pci, using reflections here: same values as py-ecomplexity package\n    cm <- complexity_measures(bi,method='reflections')\n    # convert to tibble, add country names, sort from most to least complex\n    # -- xci labels are set with setNames (extract with 'names')\n    df_eci <- cm$complexity_index_country %>%\n      as_tibble() %>%\n      mutate(country = names(cm$complexity_index_country)) %>%\n      rename(eci = value)\n    df_eci$year = yeart\n    head(df_eci)\n    df_eci_allyrs <- bind_rows(df_eci_allyrs,df_eci)\n  }\n\n# plot eci over the years\ndft <- filter(df_eci_allyrs,country == 'Ukraine')\ndft %>% ggplot(aes(x = year, y = eci)) + geom_line()"]},{"cell_type":"markdown","metadata":{},"source":["##### How does Ukraine&rsquo;s economic complexity in 2015 compare to other countries? Which countries have comparable economic complexity?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# - keep 2015, sort by eci and create row number\ndft <- df_eci_allyrs %>%\n  filter(year == 2015)  %>%\n  arrange(desc(eci)) %>%\n  mutate(row_number = row_number())\n# countries above and below Ukraine in ranking\nrow_number1 <- filter(dft,country=='Ukraine')$row_number-5\nrow_number2 <- filter(dft,country=='Ukraine')$row_number+5\n# show\ndft %>% slice(row_number1:row_number2)"]},{"cell_type":"markdown","metadata":{},"source":["##### What are the most complex products that Ukraine exported in 2015?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_ukr <- df_rca %>%\n  filter(time_col == 2015,region_col=='Ukraine',RCAcpt > 1)\n# to merge pci into the dataframe, add leading zero if 3-digit\ndf_ukr$len_product_code = str_length(df_ukr$product_code)\ndf_ukr <- df_ukr %>%\n    mutate(product_code = ifelse(len_product_code == 3, paste('0',product_code,sep=\"\"),product_code))\n# strip leading / trailing spaces\ndf_ukr$product_code <- trimws(df_ukr$product_code, which = c(\"both\"))\n# merge pcis from 2000 into dataframe\ndf_ukr <- left_join(df_ukr, df_pci, by = c(\"product_code\" = \"product_code\"))\n# sort\nhead(arrange(df_ukr,desc(pci)))\nhead(df_ukr,20)"]},{"cell_type":"markdown","metadata":{},"source":["## Questions?\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Contact me at matte \\_ hartog@hks.harvard.edu or drop by the fifth floor in the Rubenstein building, office 502.\n\n"]}],"metadata":{"org":null,"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"codemirror_mode":"r","file_extension":".r","mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.3.2"}},"nbformat":4,"nbformat_minor":0}
