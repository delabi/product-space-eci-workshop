{"cells":[{"cell_type":"markdown","metadata":{},"source":"Review session: Trade, product space and economic complexity\n============================================================\n\n"},{"cell_type":"markdown","metadata":{},"source":["September 16 2021, Matte Hartog\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Notes\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Google colab link:\n\n[https://colab.research.google.com/github/matteha/product-space-eci-workshop/blob/main/product-space-eci-workshop.ipynb](https://colab.research.google.com/github/matteha/product-space-eci-workshop/blob/main/product-space-eci-workshop.ipynb)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## To do first\n\n"]},{"cell_type":"markdown","metadata":{},"source":["In Google Colab:\n\n1.  Turn on Table of Contents: (in browser, click on &rsquo;View&rsquo; in top, then &rsquo;Table of Contents&rsquo;)\n\n2.  Expand all sections (&rsquo;View&rsquo; > &rsquo;Expand Sections&rsquo; if not greyed out)\n\n(In Google Colab equations will show up properly, in github they don&rsquo;t work)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Outline of lab session\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Introduction to trade data\n\n-   Calculating RCAs, product co-occurences and product proximity, density / density regressions\n\n-   Product space visualization\n\n-   Calculating Economic Complexity / Product Complexity\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Trade data\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Background\n\n"]},{"cell_type":"markdown","metadata":{},"source":["The product space is, as well as its derivations / related measures such as economic complexity and the Growth&rsquo;s annual rankings of countries by economic complexity (at [https://atlas.cid.harvard.edu](https://atlas.cid.harvard.edu)), are based on trade data between countries.\n\nThe Growth Lab maintains and periodically updates a cleaned version of trade data at Harvard Dataverse:\n\n[https://dataverse.harvard.edu/dataverse/atlas](https://dataverse.harvard.edu/dataverse/atlas)\n\nThis dataset contains bilateral trade data among 235 countries and territories in thousands of different products categories (a description of the data can be found at: [http://atlas.cid.harvard.edu/downloads](http://atlas.cid.harvard.edu/downloads)).\n\nHow does the data look like? We will explore the data in Python using the &rsquo;pandas&rsquo; (most popular Python package for data analysis).\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Footnote on trade and services (ICT, tourism, etc.):\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Services and tourism are included in the Growth Lab&rsquo;s Atlas and trade data as well as of September 2018. See announcement at:\n\n[https://atlas.cid.harvard.edu/announcements/2018/services-press-release](https://atlas.cid.harvard.edu/announcements/2018/services-press-release)\n\nObtained from IMF, trade in services covers four categories of economic activities between producers and consumers across borders:\n\n-   services supplied from one country to another (e.g. call centers)\n-   consumption in other countries (e.g. international tourism)\n-   firms with branches in other countries (e.g. bank branches overseas)\n-   individuals supplying services in another country (e.g. IT consultant abroad)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Load necessary Python libraries\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# -- Global settings\n# - import python libraries necessary for this workshop\n# suppress warnings on google colab for now\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# to interact with os, e.g. to execute shell comands such as 'ls', 'pwd' etc.\nimport os\n# to do data processing\nimport pandas as pd\n# backend of pandas, working with matrices\nimport numpy as np\n# to visualize data (in pandas)\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as colors\n# to process a json file\nimport json\n# work with regex in python\nimport re\n# work with networks in python, to create product space\nimport networkx as nx\n# python tools to work with combinations of arrays\nfrom itertools import count\nfrom itertools import combinations\nfrom itertools import product\n# to run regressions\nimport statsmodels.api as sm\n# to download files\nimport urllib.request, json\n# -- set scientific notation to display numbers fully rather than exponential\npd.set_option('display.float_format', '{:.2f}'.format)\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all' # Show all results of jupyter\nimport seaborn as sns\nsns.set_style('whitegrid') # Display grids on dark background\n# Enlarged pandas display - more colums and rows with greater width\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 100000)\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_colwidth',300)\nprint('necessary libraries loaded')"]},{"cell_type":"markdown","metadata":{},"source":["### Download trade dataset and load into memory\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Load the necessary data into pandas\n\n# In pandas terminilogy this is called a 'dataframe' (df)\nproduct_classification = 'hs' # Harmonized System 1992; alternative is 'SITC - Standard Industrial Trade Classification'\n\nN_digits = '4' # alternative is 2 or 6, the higher the more detailed product info\n\n\n# Trade data: we're using s3 storage from Amazon here because we can directly download the data into pandas in Google Colab but this is no longer maintained by the Growth Lab - rather download from Dataverse.\n\ndata_url = f\"https://intl-atlas-downloads.s3.amazonaws.com/country_{product_classification}product{N_digits}digit_year.csv.zip\"\nprint('Downloading data and loading into memory')\ndf_orig = pd.read_csv(data_url, compression=\"zip\", low_memory=False)\n\n# Fix product label strings ('hs_product_name_short_en') (some products with different product codes erronuously have the same strings - hence remove these duplicates)\n# e.g. product codes 5209 and 5211 in Zimbabwe have same product string\n# download original UN classification\nwith urllib.request.urlopen(\"https://comtrade.un.org/data/cache/classificationH0.json\") as url:\n    hs1992_json = json.loads(url.read())\ndft = pd.DataFrame.from_dict(hs1992_json['results'])[['text']]\ndft['hs_product_code'] = dft['text'].str.split('-').str[0].str.strip()\ndft['hs_product_name_short_en'] = dft['text'].str.split('-',1).str[1].str.strip()\ndft['N_dig'] = dft['hs_product_code'].str.len()\ndft2 = dft[dft['N_dig']==int(N_digits)].copy()\ndf_orig = pd.merge(df_orig,dft2[['hs_product_code','hs_product_name_short_en']],how='left',on=f'hs_product_code') # unmerged are services (obtained from IMF)\n# replace product name now with downloaded strings (if not missing in either)\ndf_orig['hs_product_name_short_en_new'] = df_orig['hs_product_name_short_en_x']\ndf_orig.loc[ df_orig['hs_product_name_short_en_y'].notnull(),'hs_product_name_short_en_new'] = df_orig['hs_product_name_short_en_y']\ndf_orig.drop(['hs_product_name_short_en_x'],axis=1,inplace=True,errors='ignore')\ndf_orig.drop(['hs_product_name_short_en_y'],axis=1,inplace=True,errors='ignore')\ndf_orig.rename(columns={f'hs_product_name_short_en_new':f'hs_product_name_short_en'}, inplace=True)\n\n# Cross check that each row is a unique year-location-product entry\ndf_orig['count'] = 1\ndf_orig['sum'] = df_orig.groupby(['year','location_name_short_en','hs_product_name_short_en'])['count'].transform('sum')\nif df_orig['sum'].max() != 1:\n    print(f'duplicates found, stopping')\n    stop\n\n# rename variable names for convenience\ndf_orig.rename(columns={f'location_name_short_en':f'country_name'}, inplace=True)\ndf_orig.rename(columns={f'location_code':f'country_code'}, inplace=True)\ndf_orig.rename(columns={f'hs_product_code':f'product_code'}, inplace=True)\ndf_orig.rename(columns={f'hs_product_name_short_en':f'product_name'}, inplace=True)\n\n# Keep only relevant columns\ndf_orig = df_orig[['year',\n         'country_code',\n         'country_name',\n         'product_code',\n         'product_name',\n         'export_value']]\n\nprint('trade dataset ready')"]},{"cell_type":"markdown","metadata":{},"source":["### Exploring the trade data\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Structure of dataset\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# show 5 random rows\ndf_orig.sample(n=5)"]},{"cell_type":"markdown","metadata":{},"source":["#### What years are in the data?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_orig['year'].unique()"]},{"cell_type":"markdown","metadata":{},"source":["#### How many products are in the data?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_orig['product_name'].nunique()"]},{"cell_type":"markdown","metadata":{},"source":["#### Finding specific countries / products based on partial string matching\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"# [goto error]\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\n/tmp/ipykernel_10002/3130682011.py in <module>\n      1 STRING = 'Netherland'\n----> 2 df_orig[df_orig['country_name'].str.contains(STRING)][['country_name']].drop_duplicates()\n      3 \n      4 # Can also include regex expressions here, e.g. to ignore lower/uppercase ('wine' vs 'Wine')\n      5 STRING = 'wine'\n\nNameError: name 'df_orig' is not defined"}],"source":["STRING = 'Netherland'\ndf_orig[df_orig['country_name'].str.contains(STRING)][['country_name']].drop_duplicates()\n\n# Can also include regex expressions here, e.g. to ignore lower/uppercase ('wine' vs 'Wine')\nSTRING = 'wine'\ndf_orig[df_orig['product_name'].str.contains(STRING,flags=re.IGNORECASE, regex=True)][['product_name']].drop_duplicates()"]},{"cell_type":"markdown","metadata":{},"source":["#### Example: What were the major export products of the USA in 2012?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# create a 'dataframe' called 'df2' with only exports from USA in 2012\ndf2 = df_orig[ (df_orig['country_code']=='USA') & (df_orig['year'] == 2012) ].copy()\n# create another dataframe 'df3' that contains the sum of exports per product\ndf3 = df2.groupby(['product_code','product_name'],as_index=False)['export_value'].sum()\n# sort\ndf3.sort_values(by=['export_value'],ascending=False,inplace=True)\n# show first 10 rows\ndf3[0:10]"]},{"cell_type":"markdown","metadata":{},"source":["#### Example: How did exports of Cars evolve over time in the USA?\n\n"]},{"cell_type":"markdown","metadata":{},"source":["From about 10 billion USD up to almost $60 billion USD.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df2 = df_orig[ (df_orig['country_code']=='USA')].copy()\n#df3 = df2[df2['product_name']=='Cars']\ndf3 = df2[df2['product_code']=='8703']\ndf3.plot(x='year', y='export_value')"]},{"cell_type":"markdown","metadata":{},"source":["## Revealed comparative advantage (RCA)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["What products are countries specialized in? For that, following Hidalgo et al. (2007), we calculate the Revealed Comparative Advantage (RCA) of each country-product pair: how much a country &rsquo;over-exports&rsquo; a product in comparison to all other countries.\n\nTechnically this is the Balassa index of comparative advantage, calculated as follows for product $p$ and country $c$ at time $t$:\n\n\\begin{equation} \\label{e_RCA}\n{RCA}_{cpt}=\\frac{X_{cpt}/X_{ct}}{X_{pt}/X_{t}}\n\\tag{1}\n\\end{equation}\n\nwhere $X_{cpt}$ represents the total value of country $c$’s exports of product $p$ at time $t$ across all importers. An omitted subscript indicates a summation over the omitted dimension, e.g.: $X_{t}=\\sum \\limits_{c,p,t} X_{cpt}$.\n\nA product-country pair with $RCA>1$ means that the product is over-represented in the country&rsquo;s export basket.\n\nWe use the original trade dataset (&rsquo;df<sub>orig</sub>&rsquo;) that is loaded into memory:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["def calc_rca(data,country_col,product_col,time_col,value_col):\n    \"\"\"\n    Calculates Revealed Comparative Advantage (RCA) of country-product-time combinations\n\n    Returns:\n        pandas dataframe with RCAs\n    \"\"\"\n\n    # Aggregate to country-product-time dataframe\n    print('creating all country-product-time combinations')\n    # - add all possible products for each country with export value 0\n    # - else matrices later on will have missing values in them, complicating calculations\n    df_all = pd.DataFrame(list(product(data[time_col].unique(), data[country_col].unique(),data[product_col].unique())))\n    df_all.columns=[time_col,country_col,product_col]\n    print('merging data in')\n    df_all = pd.merge(df_all,data[[time_col,country_col,product_col,value_col]],how='left',on=[time_col,country_col,product_col])\n    df_all.loc[df_all[value_col].isnull(),value_col] = 0\n\n    # Calculate the properties\n    print('calculating properties')\n    df_all['Xcpt'] = df_all[value_col]\n    df_all['Xct'] = df_all.groupby([country_col, time_col])[value_col].transform(sum)\n    df_all['Xpt'] = df_all.groupby([product_col, time_col])[value_col].transform(sum)\n    df_all['Xt'] = df_all.groupby([time_col])[value_col].transform('sum')\n    df_all['RCAcpt'] = (df_all['Xcpt']/df_all['Xct'])/(df_all['Xpt']/df_all['Xt'])\n    df_all.drop(['Xcpt','Xct','Xpt','Xt'],axis=1,inplace=True,errors='ignore')\n\n    return df_all\n\ndf_rca = calc_rca(data=df_orig,country_col='country_name',product_col='product_name',time_col='year',value_col='export_value')\n\nprint('rca dataframe ready')\n\n# show results\ndf_rca[0:10]"]},{"cell_type":"markdown","metadata":{},"source":["### Example: What products are The Netherlands and Saudi Arabia specialized in, in 2000?\n\n"]},{"cell_type":"markdown","metadata":{},"source":["(Note that different commands are chained together here; can also be ran separately)\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# The Netherlands\nprint(\"\\n The Netherlands: \\n\")\n\ndf_rca[ (df_rca['year']==2000) & (df_rca['country_name']=='Netherlands')].sort_values(by=['RCAcpt'],ascending=False)[['product_name','RCAcpt','year']][0:5]\n\nprint(\"\\n Saudi Arabia:\\n\")\n\n# Saudi Arabia\ndf_rca[ (df_rca['year']==2000) & (df_rca['country_name']=='Saudi Arabia')].sort_values(by=['RCAcpt'],ascending=False)[['product_name','RCAcpt','year']][0:5]"]},{"cell_type":"markdown","metadata":{},"source":["## Product proximity (based on co-occurences)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Calculating product co-occurences\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Knowing which countries are specialized in which products, the next step analyzes the extent to which two products are over-represented ($RCA>1$) in the same countries.\n\nAs noted in the lecture, the main insight supporting this inference is that countries will produce combinations of products that require similar capabilities.\n\nHence we infer capabilities from trade patterns, because the capabilities of a country is a priori hard to determine and capabilities themselves are hard to observe.\n\nHence, **the degree to which two products cooccur in the export baskets of the same countries provides an indication of how similar the capability requirements of the two products are**.\n\nWe will calculate the co-occurence matrix of products below.\n\nFirst, a product is &rsquo;present&rsquo; in a country if the country exports the product with $RCA>1$:\n\n\\begin{equation} \\label{e_presence}\nM_{cp}=\\begin{cases}\n    1 & \\text{if ${RCA}_{cp}>1$}; \\\\\n    0 & \\text{elsewhere.}\n    \\end{cases}\n\\tag{2}\n\\end{equation}\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_rca['Mcp'] = 0\ndf_rca.loc[df_rca['RCAcpt']>1,'Mcp'] = 1"]},{"cell_type":"markdown","metadata":{},"source":["Next, we calculate how often two products are present in the same countries, using the Mcp threshold:\n\n\\begin{equation} \\label{e_cooc}\nC<sub>pp&rsquo;</sub>=&sum; \\limits<sub>c</sub> M<sub>cp</sub> M<sub>cp&rsquo;</sub>\n\\tag{3}\n\\end{equation]\n\nWe will use the first year of data in the dataset, **1995,** below.\n\nNote that to reduce yearly votality, Hidalgo et al. (2007) aggregate the trade data across multiple years (1998-2000) when calculating RCAs and product proximities for the product space. (However, when comparing the product space across years, they do use individual years).\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["def calc_cpp(data,country_col,product_col):\n    \"\"\"\n    Calculates product co-occurences in countries\n\n    Returns:\n        pandas dataframe with co-occurence value for each product pair\n    \"\"\"\n\n    # Create combinations within country_col (i.e. countries) of entities (i.e. products)\n    dft = (data.groupby(country_col)[product_col].apply(lambda x: pd.DataFrame(list(combinations(x,2))))\n            .reset_index(level=1, drop=True)\n            .reset_index())\n    dft.rename(columns={0:f'product_1'}, inplace=True)\n    dft.rename(columns={1:f'product_2'}, inplace=True)\n\n    # Create second half of matrix (assymmetrical):\n    # product 1 X product 2 == product 2 X product 1\n    dft2 = dft.copy()\n    dft2.rename(columns={f'product_1':f'product_2t'}, inplace=True)\n    dft2.rename(columns={f'product_2':f'product_1'}, inplace=True)\n    dft2.rename(columns={f'product_2t':f'product_2'}, inplace=True)\n    dft3 = pd.concat([dft,dft2],axis=0,sort=False)\n\n    # Now calculate N of times that products occur together\n    dft3['count'] = 1\n    dft3 = dft3.groupby(['product_1','product_2'],as_index=False)['count'].sum()\n    dft3.rename(columns={f'count':f'Cpp'}, inplace=True)\n\n    return dft3\n\n# Keep only year 1995\ndft = df_rca[df_rca['year']==1995].copy()\n\n# Keep only country-product combinations where Mcp == 1 (thus RCAcp > 1)\ndft = dft[dft['Mcp']==1]\n\n# Calculate cpp\ndf_cpp = calc_cpp(dft,country_col='country_name',product_col='product_name')\n\nprint('cpp product co-occurences dataframe ready')"]},{"cell_type":"markdown","metadata":{},"source":["### Products that co-occur most often\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# -- show products that co-occur most often\ndf_cpp.sort_values(by=['Cpp'],ascending=False,inplace=True)\ndf_cpp[0:10]"]},{"cell_type":"markdown","metadata":{},"source":["### Normalize product co-occurences (cpp) as in Hidalgo et al. 2007\n\n"]},{"cell_type":"markdown","metadata":{},"source":["To get an accurate value of product proximity, we need to correct these numbers for the extent to which products are present in general in trade flows between countries.\n\nTo do so, Hidalgo et al. (2007) calculate product proximity as follows, defining it as the minimum of two conditional probabilities:\n\n\\begin{equation}\nC_{ppt'}  = \\min \\left( \\frac{C_{pp'}}{C_{p}},\\frac{C_{pp'}}{C_{p'}} \\right)\n\\tag{4}\n\\end{equation}\n\nThe minimum here is used to elimate a &rsquo;false positive&rsquo;.\n\nHence we correct for how prevalent specialization in product $i$ and product $j$ is across countries (i.e. the &rsquo;ubiquity&rsquo; of the products).\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# We calculate the ubiquity of each product and add it to the cpp matrix, then take the minimum of conditional probabilities\n\n# again we use the year 1995 here\ndft = df_rca[df_rca['year']==1995].copy()\ndf_ub = dft.groupby(['product_name'],as_index=False)['Mcp'].sum()\ndf_ub.rename(columns={f'product_name':f'product_1'}, inplace=True)\n# merge ubiqity into cpp matrix\ndf_cppt = pd.merge(df_cpp,df_ub,how='left',on=f'product_1')\ndf_ub.rename(columns={f'product_1':f'product_2'}, inplace=True)\ndf_cppt = pd.merge(df_cppt,df_ub,how='left',on=f'product_2')\n\n# take minimum of conditional probabilities\ndf_cppt['kpi'] = df_cppt['Cpp']/df_cppt['Mcp_x']\ndf_cppt['kpj'] = df_cppt['Cpp']/df_cppt['Mcp_y']\ndf_cppt['phi'] = df_cppt['kpi']\ndf_cppt.loc[df_cppt['kpj']<df_cppt['kpi'],'phi'] = df_cppt['kpj']\n\n# show most proximate products\ndf_cppt.sort_values(by=['phi'],ascending=False,inplace=True)\ndf_cppt[0:10]"]}],"metadata":{"org":null,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}
