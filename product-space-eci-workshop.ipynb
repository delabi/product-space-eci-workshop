{"cells":[{"cell_type":"markdown","metadata":{},"source":"Lab session 2: Trade, product space and economic complexity\n===========================================================\n\n"},{"cell_type":"markdown","metadata":{},"source":["June 7 2021, Matte Hartog\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Notes\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Outline of lab session\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Introduction to trade data\n-   Calculating RCAs, product co-occurences and product proximity, density / density regressions\n-   Product space visualization\n-   Calculating Economic Complexity / Product Complexity\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## To do first\n\n"]},{"cell_type":"markdown","metadata":{},"source":["In Google Colab:\n\n1.  Turn on Table of Contents: (in browser, click on &rsquo;View&rsquo; in top, then &rsquo;Table of Contents&rsquo;)\n\n2.  Expand all sections (&rsquo;View&rsquo; > &rsquo;Expand Sections&rsquo; if not greyed out)\n\n(In Google Colab equations will show up properly)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Trade data\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Background\n\n"]},{"cell_type":"markdown","metadata":{},"source":["The product space is, as well as its derivations / related measures such as economic complexity and the Growth&rsquo;s annual rankings of countries by economic complexity (at [https://atlas.cid.harvard.edu](https://atlas.cid.harvard.edu)), are based on trade data between countries.\n\nThe Growth Lab maintains and periodically updates a cleaned version of trade data at [https://intl-atlas-downloads.s3.amazonaws.com/index.html](https://intl-atlas-downloads.s3.amazonaws.com/index.html).\n\nThis dataset contains bilateral trade data among 235 countries and territories in thousands of different products categories (a description of the data can be found at: [http://atlas.cid.harvard.edu/downloads](http://atlas.cid.harvard.edu/downloads)).\n\nHow does the data look like? We will explore the data in Python using the &rsquo;pandas&rsquo; (most popular Python package for data analysis).\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Footnote on trade and services (ICT, tourism, etc.):\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Services and tourism are included in the Growth Lab&rsquo;s Atlas and trade data as well as of September 2018. See announcement at:\n\n[https://atlas.cid.harvard.edu/announcements/2018/services-press-release](https://atlas.cid.harvard.edu/announcements/2018/services-press-release)\n\nObtained from IMF, trade in services covers four categories of economic activities between producers and consumers across borders:\n\n-   services supplied from one country to another (e.g. call centers)\n-   consumption in other countries (e.g. international tourism)\n-   firms with branches in other countries (e.g. bank branches overseas)\n-   individuals supplying services in another country (e.g. IT consultant abroad)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Load necessary Python libraries\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# -- Global settings\n# - import python libraries necessary for this workshop\n# suppress them on google colab for now\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as colors\nimport json\nimport networkx as nx\nfrom itertools import count\nfrom itertools import combinations\nfrom itertools import product\nimport statsmodels.api as sm\n# -- set scientific notation to display numbers fully rather than exponential\npd.set_option('display.float_format', '{:.2f}'.format)\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all' # Show all results of jupyter\nimport seaborn as sns\nsns.set_style('whitegrid') # Display grids on dark background\npd.set_option('display.max_columns', 500) # Broaden pandas display in jupyter console\npd.set_option('display.width', 100000)\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_colwidth',300)\nprint('necessary libraries loaded')"]},{"cell_type":"markdown","metadata":{},"source":["### Download trade dataset and load into memory\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Load the necessary data into a pandas 'dataframe' (df)\nproduct_classification = 'hs' # Harmonized System 1992; alternative is 'SITC - Standard Industrial Trade Classification'\nN_digits = '4' # alternative is 2 or 6, the higher the more detailed product info\ndata_url = f\"https://intl-atlas-downloads.s3.amazonaws.com/country_{product_classification}product{N_digits}digit_year.csv.zip\"\nprint('Downloading data and loading into memory')\ndf_orig = pd.read_csv(data_url, compression=\"zip\", low_memory=False)\n\n# Fix product label strings ('hs_product_name_short_en') (some products have erronuously duplicate strings: will contact Growth Lab's Atlas team)\n# e.g. product codes 5209 and 5211 in Zimbabwe have same product string\nimport urllib.request, json\nwith urllib.request.urlopen(\"https://comtrade.un.org/data/cache/classificationH0.json\") as url:\n    hs1992_json = json.loads(url.read())\ndft = pd.DataFrame.from_dict(hs1992_json['results'])[['text']]\ndft['hs_product_code'] = dft['text'].str.split('-').str[0].str.strip()\ndft['hs_product_name_short_en'] = dft['text'].str.split('-',1).str[1].str.strip()\ndft['N_dig'] = dft['hs_product_code'].str.len()\ndft2 = dft[dft['N_dig']==int(N_digits)].copy()\ndf_orig = pd.merge(df_orig,dft2[['hs_product_code','hs_product_name_short_en']],how='left',on=f'hs_product_code') # unmerged are services (obtained from IMF)\n# replace product name now with downloaded strings (if not missing in either)\ndf_orig['hs_product_name_short_en_new'] = df_orig['hs_product_name_short_en_x']\ndf_orig.loc[ df_orig['hs_product_name_short_en_y'].notnull(),'hs_product_name_short_en_new'] = df_orig['hs_product_name_short_en_y']\ndf_orig.drop(['hs_product_name_short_en_x'],axis=1,inplace=True,errors='ignore')\ndf_orig.drop(['hs_product_name_short_en_y'],axis=1,inplace=True,errors='ignore')\ndf_orig.rename(columns={f'hs_product_name_short_en_new':f'hs_product_name_short_en'}, inplace=True)\n\n# Cross check that each row is a unique year-location-product entry\ndf_orig['count'] = 1\ndf_orig['sum'] = df_orig.groupby(['year','location_name_short_en','hs_product_name_short_en'])['count'].transform('sum')\nif df_orig['sum'].max() != 1:\n    print(f'duplicates found, stopping')\n    stop\n\n# Keep only relevant columns\ndf_orig = df_orig[['year',\n         'location_code',\n         'location_name_short_en',\n         'hs_product_code',\n         'hs_product_name_short_en',\n         'export_value']]\n\nprint('trade dataset ready')"]},{"cell_type":"markdown","metadata":{},"source":["### Exploring the trade data\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Structure of dataset\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# show 5 random rows\ndf_orig.sample(n=5)"]},{"cell_type":"markdown","metadata":{},"source":["#### What years are in the data?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_orig['year'].unique()"]},{"cell_type":"markdown","metadata":{},"source":["#### How many products are in the data?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_orig['hs_product_name_short_en'].nunique()"]},{"cell_type":"markdown","metadata":{},"source":["#### Finding specific countries / products based on partial string matching\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["STRING = 'Netherland'\ndf_orig[df_orig['location_name_short_en'].str.contains(STRING)][['location_name_short_en']].drop_duplicates()\n\nSTRING = 'Wine'\ndf_orig[df_orig['hs_product_name_short_en'].str.contains(STRING)][['hs_product_name_short_en']].drop_duplicates()"]},{"cell_type":"markdown","metadata":{},"source":["#### Example: What were the major export products of the USA in 2012?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df2 = df_orig[ (df_orig['location_code']=='USA') & (df_orig['year'] == 2012) ].copy()\ndf3 = df2.groupby(['hs_product_code','hs_product_name_short_en'],as_index=False)['export_value'].sum()\ndf3.sort_values(by=['export_value'],ascending=False,inplace=True)\ndf3[0:10]"]},{"cell_type":"markdown","metadata":{},"source":["#### Example: How did exports of Cars evolve over time in the USA?\n\n"]},{"cell_type":"markdown","metadata":{},"source":["From about 10 billion USD up to almost $60 billion USD.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df2 = df_orig[ (df_orig['location_code']=='USA')].copy()\n#df3 = df2[df2['hs_product_name_short_en']=='Cars']\ndf3 = df2[df2['hs_product_code']=='8703']\ndf3.plot(x='year', y='export_value')"]},{"cell_type":"markdown","metadata":{},"source":["## Revealed comparative advantage (RCA)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["What products are countries specialized in? For that, following Hidalgo et al. (2007), we calculate the Revealed Comparative Advantage (RCA) of each country-product pair: how much a country &rsquo;over-exports&rsquo; a product in comparison to all other countries.\n\nTechnically this is the Balassa index of comparative advantage, calculated as follows for product $p$ and country $c$ at time $t$:\n\n\\begin{equation} \\label{e_RCA}\n{RCA}_{cpt}=\\frac{X_{cpt}/X_{ct}}{X_{pt}/X_{t}}\n\\tag{1}\n\\end{equation}\n\nwhere $X_{cpt}$ represents the total value of country $c$â€™s exports of product $p$ at time $t$ across all importers. An omitted subscript indicates a summation over the omitted dimension, e.g.: $X_{t}=\\sum \\limits_{c,p,t} X_{cpt}$.\n\nA product-country pair with $RCA>1$ means that the product is over-represented in the country&rsquo;s export basket.\n\nWe use the original trade dataset (&rsquo;df<sub>orig</sub>&rsquo;) that is loaded into memory:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["def calc_rca(data,country_col,product_col,time_col,value_col):\n    \"\"\"\n    Calculates Revealed Comparative Advantage (RCA) of country-product-time combinations\n\n    Returns:\n        pandas dataframe with RCAs\n    \"\"\"\n\n    # Aggregate to country-product-time dataframe\n    print('creating all country-product-time combinations')\n    # - add all possible products for each country with export value 0\n    # - else matrices later on will have missing values in them, complicating calculations\n    df_all = pd.DataFrame(list(product(data[time_col].unique(), data[country_col].unique(),data[product_col].unique())))\n    df_all.columns=[time_col,country_col,product_col]\n    print('merging data in')\n    df_all = pd.merge(df_all,data[[time_col,country_col,product_col,value_col]],how='left',on=[time_col,country_col,product_col])\n    df_all.loc[df_all[value_col].isnull(),value_col] = 0\n\n    # Calculate the properties\n    print('calculating properties')\n    df_all['Xcpt'] = df_all[value_col]\n    df_all['Xct'] = df_all.groupby([country_col, time_col])[value_col].transform(sum)\n    df_all['Xpt'] = df_all.groupby([product_col, time_col])[value_col].transform(sum)\n    df_all['Xt'] = df_all.groupby([time_col])[value_col].transform('sum')\n    df_all['RCAcpt'] = (df_all['Xcpt']/df_all['Xct'])/(df_all['Xpt']/df_all['Xt'])\n    df_all.drop(['Xcpt','Xct','Xpt','Xt'],axis=1,inplace=True,errors='ignore')\n\n    return df_all\n\ndf_rca = calc_rca(data=df_orig,country_col='location_name_short_en',product_col='hs_product_name_short_en',time_col='year',value_col='export_value')\n\nprint('rca dataframe ready')\n\n# show results\ndf_rca[0:10]"]},{"cell_type":"markdown","metadata":{},"source":["### Example: What products are The Netherlands and Saudi Arabia specialized in, in 2000?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# The Netherlands\nprint(\"\\n The Netherlands: \\n\")\n\ndf_rca[ (df_rca['year']==2000) & (df_rca['location_name_short_en']=='Netherlands')].sort_values(by=['RCAcpt'],ascending=False)[['hs_product_name_short_en','RCAcpt','year']][0:5]\n\nprint(\"\\n Saudi Arabia:\\n\")\n\n# Saudi Arabia\ndf_rca[ (df_rca['year']==2000) & (df_rca['location_name_short_en']=='Saudi Arabia')].sort_values(by=['RCAcpt'],ascending=False)[['hs_product_name_short_en','RCAcpt','year']][0:5]"]},{"cell_type":"markdown","metadata":{},"source":["## Product proximity (based on co-occurences)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Calculating product co-occurences\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Knowing which countries are specialized in which products, the next step analyzes the extent to which two products are over-represented ($RCA>=1$) in the same countries.\n\nAs noted in the lecture, the main insight supporting this inference is that countries will produce combinations of products that require similar capabilities.\n\nHence we infer capabilities from trade patterns, because the capabilities of a country is a priori hard to determine and capabilities themselves are hard to observe.\n\nHence, **the degree to which two products cooccur in the export baskets of the same countries provides an indication of how similar the capability requirements of the two products are**.\n\nWe will calculate the co-occurence matrix of products below.\n\nFirst, a product is &rsquo;present&rsquo; in a country if the country exports the product with $RCA>=1$:\n\n\\begin{equation} \\label{e_presence}\nP_{cpt}=\\begin{cases}\n    1 & \\text{if ${RCA}_{cpt}>=1$}; \\\\\n    0 & \\text{elsewhere.}\n    \\end{cases}\n\\tag{2}\n\\end{equation}\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df_rca['Pcpt'] = 0\ndf_rca.loc[df_rca['RCAcpt']>=1,'Pcpt'] = 1"]},{"cell_type":"markdown","metadata":{},"source":["Next, we calculate how often two products are present in the same countries, using the Pcp threshold:\n\n\\begin{equation} \\label{e_cooc}\nC_{pp'}=\\sum \\limits_{c} P_{cp} P_{cp'}\n\\tag{3}\n\\end{equation}\n\nWe will use the first year of data in the dataset, **1995,** below.\n\nNote that to reduce yearly votality, Hidalgo et al. (2007) aggregate the trade data across multiple years (1998-2000) when calculating RCAs and product proximities for the product space. (However, when comparing the product space across years, they do use individual years).\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["def calc_cpp(data,country_col,product_col):\n    \"\"\"\n    Calculates product co-occurences in countries\n\n    Returns:\n        pandas dataframe with co-occurence value for each product pair\n    \"\"\"\n\n    # Create combinations within country_col (i.e. countries) of entities (i.e. products)\n    dft = (data.groupby(country_col)[product_col].apply(lambda x: pd.DataFrame(list(combinations(x,2))))\n            .reset_index(level=1, drop=True)\n            .reset_index())\n    dft.rename(columns={0:f'product_1'}, inplace=True)\n    dft.rename(columns={1:f'product_2'}, inplace=True)\n\n    # Create second half of matrix (assymmetrical):\n    # product 1 X product 2 == product 2 X product 1\n    dft2 = dft.copy()\n    dft2.rename(columns={f'product_1':f'product_2t'}, inplace=True)\n    dft2.rename(columns={f'product_2':f'product_1'}, inplace=True)\n    dft2.rename(columns={f'product_2t':f'product_2'}, inplace=True)\n    dft3 = pd.concat([dft,dft2],axis=0,sort=False)\n\n    # Now calculate N of times that products occur together\n    dft3['count'] = 1\n    dft3 = dft3.groupby(['product_1','product_2'],as_index=False)['count'].sum()\n    dft3.rename(columns={f'count':f'Cpp'}, inplace=True)\n\n    return dft3\n\n# Keep only year 1995\ndft = df_rca[df_rca['year']==1995].copy()\n\n# Keep only country-product combinations where Pcp == 1 (thus RCAcp >= 1)\ndft = dft[dft['Pcpt']==1]\n\n# Calculate cpp\ndf_cpp = calc_cpp(dft,country_col='location_name_short_en',product_col='hs_product_name_short_en')\n\nprint('cpp product co-occurences dataframe ready')"]},{"cell_type":"markdown","metadata":{},"source":["### Products that co-occur most often\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# -- show products that co-occur most often\ndf_cpp.sort_values(by=['Cpp'],ascending=False,inplace=True)\ndf_cpp[0:10]"]},{"cell_type":"markdown","metadata":{},"source":["### Normalize product co-occurences (cpp) as in Hidalgo et al. 2007\n\n"]},{"cell_type":"markdown","metadata":{},"source":["To get an accurate value of product proximity, we need to correct these numbers for the extent to which products are present in general in trade flows between countries.\n\nTo do so, Hidalgo et al. (2007) calculate product proximity as follows, defining it as the minimum of two conditional probabilities:\n\n\\begin{equation}\nC_{ppt'}  = \\min \\left( \\frac{C_{pp'}}{C_{p}},\\frac{C_{pp'}}{C_{p'}} \\right)\n\\tag{4}\n\\end{equation}\n\nThe minimum here is used to elimate a &rsquo;false positive&rsquo;.\n\nHence we correct for how prevalent specialization in product $i$ and product $j$ is across countries (i.e. the &rsquo;ubiquity&rsquo; of the products).\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# We calculate the ubiquity of each product and add it to the cpp matrix, then take the minimum of conditional probabilities\n\n# again we use the year 1995 here\ndft = df_rca[df_rca['year']==1995].copy()\ndf_ub = dft.groupby(['hs_product_name_short_en'],as_index=False)['Pcpt'].sum()\ndf_ub.rename(columns={f'hs_product_name_short_en':f'product_1'}, inplace=True)\n# merge ubiqity into cpp matrix\ndf_cppt = pd.merge(df_cpp,df_ub,how='left',on=f'product_1')\ndf_ub.rename(columns={f'product_1':f'product_2'}, inplace=True)\ndf_cppt = pd.merge(df_cppt,df_ub,how='left',on=f'product_2')\n\n# take minimum of conditional probabilities\ndf_cppt['kpi'] = df_cppt['Cpp']/df_cppt['Pcpt_x']\ndf_cppt['kpj'] = df_cppt['Cpp']/df_cppt['Pcpt_y']\ndf_cppt['phi'] = df_cppt['kpi']\ndf_cppt.loc[df_cppt['kpj']<df_cppt['kpi'],'phi'] = df_cppt['kpj']\n\n# show most proximate products\ndf_cppt.sort_values(by=['phi'],ascending=False,inplace=True)\ndf_cppt[0:10]"]},{"cell_type":"markdown","metadata":{},"source":["## Product space\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Overview\n\n"]},{"cell_type":"markdown","metadata":{},"source":["We now have a measure of similarity between products, which is the core of the product space.\n\n[https://atlas.cid.harvard.edu/explore/network?country=114&year=2018&productClass=HS&product=undefined&startYear=undefined&target=Product&partner=undefined](https://atlas.cid.harvard.edu/explore/network?country=114&year=2018&productClass=HS&product=undefined&startYear=undefined&target=Product&partner=undefined)\n\n![img](/home/linux/Dropbox/proj/org_zhtml_projects/product-space-eci-workshop/imgs/product_space_atlas_website.png)\n\n![img](https://www.dropbox.com/s/izag1xf28yldanf/product_space_atlas_website.png?dl=1)\n\nBelow we will explore the product space using Python. The Github repo for this is available at [https://github.com/matteha/py-productspace](https://github.com/matteha/py-productspace).\n\nWhat we need is information on:\n\n-   Edges (ties) between nodes\n    \n    Ties between nodes represent the product proximity calculated above. Each product pair has a proximity value, but visualizing all ties, however, would result in a major &ldquo;hairball&rdquo;.\n    \n    To determine which of the ties to visualize in the product space, a &rsquo;maximum spanning tree algorithm&rsquo; is used (to make sure all nodes are connected directly or indirectly) in conjunction with a certain proximity threshold (0.55 minimum conditional probability). The details can be found in the Supplementary Material of Hidalgo et al. (2007) at [https://science.sciencemag.org/content/suppl/2007/07/26/317.5837.482.DC1](https://science.sciencemag.org/content/suppl/2007/07/26/317.5837.482.DC1).\n\n-   Position of nodes\n    -   Each node is a product\n    \n    -   To position them in the product space, Hidalgo et al. (2007) used a spring embedding algorithm (which positions the nodes in such a way that there are as few crossing ties as possible, using physical simulations with force-directed algorithms), followed by hand-crafting the outcome to further visually separate distinct &rsquo;clusters&rsquo; of products.\n        \n        We will use this fixed layout for now (Yang Li&rsquo;s workshop will deal with different ways to visualize multi-dimensional data in 2D/3D, e.g. with machine learning, UMAP).\n        \n        The data on the position of nodes (x, y coordinates) is available in the Atlas data repository at:\n        [https://dataverse.harvard.edu/file.xhtml?persistentId=doi:10.7910/DVN/FCDZBN/QSEETD&version=1.1](https://dataverse.harvard.edu/file.xhtml?persistentId=doi:10.7910/DVN/FCDZBN/QSEETD&version=1.1)\n        \n        We can directly load it into Python using the link below (temporarily for this workshop, when using Harvard&rsquo;s dataverse you&rsquo;d need to sign a short User Agreement form so you can&rsquo;t load data directly from a URL):\n        \n        [https://www.dropbox.com/s/r601tjoulq1denf/network_hs92_4digit.json?dl=1](https://www.dropbox.com/s/r601tjoulq1denf/network_hs92_4digit.json?dl=1)\n\n-   Size of nodes\n    \n    The size in the product space represents the total $ in world trade, but one can also use other attributes of nodes (e.g. if nodes are industries, the size could be total employment).\n\n-   Color of nodes\n    \n    In the product space the node color represents major product groups (e.g. Agriculture, Chemicals) following the Leamer classification. The node coloring data is available in the Atlas data repository at:\n    [https://dataverse.harvard.edu/dataverse/atlas?q=&types=files&sort=dateSort&order=desc&page=1](https://dataverse.harvard.edu/dataverse/atlas?q=&types=files&sort=dateSort&order=desc&page=1)\n    \n    We can directly load it into Python using the link below (again, temporary for this workshop):\n    \n    [https://www.dropbox.com/s/rlm8hu4pq0nkg63/hs4_hex_colors_intl_atlas.csv?dl=1](https://www.dropbox.com/s/rlm8hu4pq0nkg63/hs4_hex_colors_intl_atlas.csv?dl=1)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Product space in Python\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Function to create product space\n\n"]},{"cell_type":"markdown","metadata":{},"source":["The function below creates the product space. It uses the networkx package which Sultan elaborated on in the first Python session.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["def create_product_space(df_plot_dataframe=None,\n                         df_plot_node_col=['node'],\n                         df_node_size_col=None,\n                         show_legend = 0):\n\n    # Copy dataframe so original won't be overwritten\n    df_plot =  df_plot_dataframe.copy()\n\n    NORMALIZE_NODE_SIZE = 1\n    if NORMALIZE_NODE_SIZE == 1:\n\n        \"\"\"\n        The distribution of export values is highly skewed, which makes it hard to visualize\n        them properly (certain products will overshadow the rest of the network).\n\n\n        We create a new size column below in which we normalize the export values.\n        \"\"\"\n\n        ### Normalize node size (0.1 to 1)\n\n        def normalize_col(dft,col,minsize=0.1,maxsize=1):\n            \"\"\"\n            Normalizes column values with largest and smallest values capped at min at max\n            For use in networkx\n\n            returns pandas column\n            \"\"\"\n\n            alpha = maxsize-minsize\n            Xl = dft[dft[col]>0][col].quantile(0.10)\n            Xh = dft[dft[col]>0][col].quantile(0.95)\n            dft['node_size'] = 0\n            dft.loc[ dft[col]>=Xh,'node_size'] = maxsize\n            dft.loc[ (dft[col]<=Xl) & (dft[col]!=0),'node_size'] = minsize\n            dft.loc[ (dft[col]<Xh) & (dft[col]>Xl),'node_size'] = ((alpha*(dft[col]-Xl))/(Xh-Xl))+(1-alpha)\n            dft.loc[ (dft[col]<Xh) & (dft[col]>0),'node_size'] = ((alpha*(dft[col]-Xl))/(Xh-Xl))+(1-alpha)\n\n            return dft['node_size']\n\n        df_plot['node_size'] = normalize_col(df_plot,df_node_size_col,minsize=0.1,maxsize=1)\n\n    ADD_COLORS_ATLAS = 1\n    if ADD_COLORS_ATLAS == 1:\n\n        # First add product codes from original file (full strings were used for illustrative purposes above but we need the actual codes to merge data from other sources, e.g. node colors)\n        df_plot = pd.merge(df_plot,df_orig[['hs_product_name_short_en','hs_product_code']].drop_duplicates(),how='left',on='hs_product_name_short_en')\n        dft = pd.read_csv('https://www.dropbox.com/s/rlm8hu4pq0nkg63/hs4_hex_colors_intl_atlas.csv?dl=1')\n\n        # Transform hs_product_code into int (accounts for missing in pandas, if necessary)\n        # keep only numeric hs_product_codes (this drops 'unspecified' as well as services for now;\n        # - as the latter needs a separate color classification)\n        df_plot = df_plot[df_plot['hs_product_code'].astype(str).str.isnumeric()]\n        # -- also drop 9999 product code; unknown\n        df_plot = df_plot[df_plot['hs_product_code'].astype(str)!='9999']\n        # -- to allow merge, rename and transform both variables into int\n        dft['hs4'] = dft['hs4'].astype(int)\n        df_plot['hs_product_code'] = df_plot['hs_product_code'].astype(int)\n        if 'color' in df_plot.columns:\n            df_plot.drop(['color'],axis=1,inplace=True,errors='ignore')\n        df_plot = pd.merge(df_plot,dft[['hs4','color']],how='left',left_on='hs_product_code',right_on='hs4')\n        # drop column merged from dft\n        df_plot.drop(['hs4'],axis=1,inplace=True,errors='ignore')\n\n        CREATE_LEGEND = 1\n        if CREATE_LEGEND == 1:\n            # Atlas classification products\n            df_temp = pd.read_csv('https://raw.githubusercontent.com/cid-harvard/classifications/master/product/HS/IntlAtlas/out/hs92_atlas.csv')\n            df_temp.rename(columns={'Unnamed: 0': 'internal_code'}, inplace=True)\n            # -- keep sections\n            df_temp1 = df_temp[df_temp['level']=='section'].copy()\n            # -- keep 4 digit\n            df_temp2 = df_temp[df_temp['level']=='2digit'].copy()\n            # -- keep 4 digit\n            df_temp3 = df_temp[df_temp['level']=='4digit'].copy()\n            # -- merge parent id of parent id of 4 digits (= 2digit)\n            # ---- remake to float\n            df_temp3['parent_id'] = df_temp3['parent_id'].astype(object)\n            df_temp2['internal_code'] = df_temp2['internal_code'].astype(object)\n            df_temp3t = pd.merge(df_temp3,df_temp2[['internal_code','parent_id']],how='left',left_on='parent_id',right_on='internal_code',indicator=True)\n            # -- now merge parent_id_y to internal code of df_temp1\n            df_temp3t.drop(['_merge'],axis=1,inplace=True)\n            df_temp3t2 = pd.merge(df_temp3t,df_temp1[['internal_code','name']],how='left',left_on='parent_id_y',right_on='internal_code',indicator=True)\n            # keep only relevant columns\n            df_temp4 = df_temp3t2[['code','name_x','name_y']]\n            df_temp5 = df_temp4[['code','name_y']]\n            df_temp5.rename(columns={'code': 'product'}, inplace=True)\n            df_temp5.rename(columns={'name_y': 'name_sector_atlas'}, inplace=True)\n            # drop XXXX / services (not in product space)\n            drop_categories = ['XXXX','unspecified','travel','transport','ict','financial']\n            df_temp5 = df_temp5[ ~(df_temp5['product'].isin(drop_categories))]\n\n            # add to df_temp_plot\n            df_temp_plott = df_plot.copy()\n            df_temp_plott['hs_product_code'] = df_temp_plott['hs_product_code'].astype(float)\n            df_temp5['product'] = df_temp5['product'].astype(float)\n            df_temp_plot3 = pd.merge(df_temp_plott,df_temp5,how='left',left_on='hs_product_code',right_on='product')\n            df_temp_plot3.drop_duplicates(subset='color',inplace=True)\n            df_temp_plot3 = df_temp_plot3[['color','name_sector_atlas']]\n\n            # create color dict for legend\n            color_dict = {}\n            df_temp_plot3.reset_index(inplace=True,drop=True)\n            for ind, row in df_temp_plot3.iterrows():\n                color_dict[row['name_sector_atlas']] = row['color']\n\n            \"\"\"\n            def build_legend(data):\n                # Build a legend for matplotlib plt from dict\n                legend_elements = []\n                for key in data:\n                    legend_elements.append(Line2D([0], [0], marker='o', color='w', label=key,\n                                                    markerfacecolor=data[key], markersize=10))\n                return legend_elements\n            fig,ax = plt.subplots(1)\n            #ax.add_patch(rect) # Add the patch to the Axes\n            legend_elements = build_legend(color_dict)\n            ax.legend(handles=legend_elements, loc='upper left')\n            plt.show()\n            \"\"\"\n\n    ADD_NODE_POSITIONS_ATLAS = 1\n    if ADD_NODE_POSITIONS_ATLAS == 1:\n\n        # Load position of nodes (x, y coordinates of nodes from original Atlas file)\n        import urllib.request, json\n        with urllib.request.urlopen(\"https://www.dropbox.com/s/r601tjoulq1denf/network_hs92_4digit.json?dl=1\") as url:\n            networkjs = json.loads(url.read().decode())\n\n    CREATE_NETWORKX_OBJECT_AND_PLOT = 1\n    if CREATE_NETWORKX_OBJECT_AND_PLOT == 1:\n\n        # Convert json into python list and dictionary\n        nodes = []\n        nodes_pos = {}\n        for x in networkjs['nodes']:\n            nodes.append(int(x['id']))\n            nodes_pos[int(x['id'])] = (int(x['x']),-int(x['y']/1.5))\n\n        # Define product space edge list (based on strength from the json)\n        edges = []\n        for x in networkjs['edges']:\n            if x['strength'] > 1 or 1 == 1:\n                edges.append((int(x['source']),int(x['target'])))\n        dfe = pd.DataFrame(edges)\n        dfe.rename(columns={0: 'src'}, inplace=True)\n        dfe.rename(columns={1: 'trg'}, inplace=True)\n\n        # Only select edges of nodes that are also present in product space\n        dfe2 = pd.DataFrame(np.append(dfe['src'].values,dfe['trg'].values)) # (some products may not be in there)\n        dfe2.drop_duplicates(inplace=True)\n        dfe2.rename(columns={0: 'node'}, inplace=True)\n        dfn2 = pd.merge(df_plot,dfe2,how='left',left_on=df_plot_node_col,right_on='node',indicator=True)\n\n        # Drop products from this dataframe that are not in product space\n        dfn2 = dfn2[dfn2['_merge']=='both']\n\n        # Create networkx objects in Python\n\n        # G object = products that will be plotted\n        G=nx.from_pandas_edgelist(dfn2,'hs_product_code','hs_product_code')\n\n        # G2 object = all nodes and edges from the original product space\n        # - Those that are not plotted will be gray in the background,\n        # - e.g. products for which there is no info\n        G2=nx.from_pandas_edgelist(dfe,'src','trg')\n\n        # Add node attributes to networkx objects\n        # - Create a 'present' variable which indicates that these products are present in product space,\n        # - as not all products in product space are present in the data to be plotted\n        # - (e.g. because we could filter only to plot products with more than >$40 million in trade)\n        df_plot['present'] = 1\n        ATTRIBUTES = ['node_size'] + ['color'] + ['present']\n        for ATTRIBUTE in ATTRIBUTES:\n            dft = df_plot[[df_plot_node_col,ATTRIBUTE]]\n            dft['count'] = 1\n            dft = dft.groupby([df_plot_node_col,ATTRIBUTE],as_index=False)['count'].sum()\n            #** drop if missing , and drop duplicates\n            dft.dropna(inplace=True)\n            dft.drop(['count'],axis=1,inplace=True)\n            dft.drop_duplicates(subset=[df_plot_node_col,ATTRIBUTE],inplace=True)\n            dft.set_index(df_plot_node_col,inplace=True)\n            dft_dict = dft[ATTRIBUTE].to_dict()\n            for i in sorted(G.nodes()):\n                try:\n                    #G.node[i][ATTRIBUTE] = dft_dict[i]\n                    G.nodes[i][ATTRIBUTE] = dft_dict[i]\n                except Exception:\n                    #G.node[i][ATTRIBUTE] = 'Missing'\n                    G.nodes[i][ATTRIBUTE] = 'Missing'\n            for i in sorted(G2.nodes()):\n                try:\n                    #G2.node[i][ATTRIBUTE] = dft_dict[i]\n                    G2.nodes[i][ATTRIBUTE] = dft_dict[i]\n                except Exception:\n                    #G2.node[i][ATTRIBUTE] = 'Missing'\n                    G2.nodes[i][ATTRIBUTE] = 'Missing'\n\n        # Cross-check that attributes have been added correctly\n        # nx.get_node_attributes(G2,df_color)\n        # nx.get_node_attributes(G,df_color)\n\n        # Create color + size lists which networkx uses for plotting\n        groups = set(nx.get_node_attributes(G2,'color').values())\n        mapping = dict(zip(sorted(groups),count()))\n        nodes = G.nodes()\n        nodes2 = G2.nodes()\n        #colorsl = [G.node[n]['color'] for n in nodes]\n        colorsl = [G.nodes[n]['color'] for n in nodes]\n        #colorsl2 = [G2.node[n]['color'] for n in nodes2]\n        colorsl2 = [G2.nodes[n]['color'] for n in nodes2]\n        SIZE_VARIABLE = 'node_size'\n        #sizesl = [G.node[n][SIZE_VARIABLE] for n in nodes]\n        sizesl = [G.nodes[n][SIZE_VARIABLE] for n in nodes]\n        # Adjust value below to increase the PLOTTED size of nodes, depending on the resolution of the final plot\n        # (e.g. if you want to zoom in into the product space and thus set a higher resolution, you may want to set this higher)\n        #sizesl2 = [G.node[n]['node_size']*350 for n in nodes]\n        sizesl2 = [G.nodes[n]['node_size']*350 for n in nodes]\n\n        # Create matplotlib object to draw the product space\n        f = plt.figure(1,figsize=(20,20))\n        ax = f.add_subplot(1,1,1)\n\n        # turn axes off\n        plt.axis('off')\n\n        # set white background\n        f.set_facecolor('white')\n\n        # draw full product space in background, transparent with small node_size\n        nx.draw_networkx(G2,nodes_pos, node_color='gray',ax=ax,node_size=10,with_labels=False,alpha=0.1)\n\n        # draw the data fed in to the product space\n        nx.draw_networkx(G,nodes_pos, node_color=colorsl,ax=ax,node_size=sizesl2,with_labels=False,alpha=1)\n\n        # save file\n        # plt.savefig(output_dir_image)\n\n        # show the plot\n        plt.show()\n\n        if show_legend == 1:\n            # show legend as well\n            def build_legend(data):\n                # Build a legend for matplotlib plt from dict\n                legend_elements = []\n                for key in data:\n                    legend_elements.append(Line2D([0], [0], marker='o', color='w', label=key,\n                                                    markerfacecolor=data[key], markersize=10))\n                return legend_elements\n            fig,ax = plt.subplots(1)\n            #ax.add_patch(rect) # Add the patch to the Axes\n            legend_elements = build_legend(color_dict)\n            ax.legend(handles=legend_elements, loc='upper left')\n            plt.show()\n\nprint('defined product space function, ready to plot')"]},{"cell_type":"markdown","metadata":{},"source":["#### Visualizing data in the product space\n\n"]},{"cell_type":"markdown","metadata":{},"source":["First we select the country we which to visualize. We&rsquo;ll search for Saudi Arabia below, using the &rsquo;audi&rsquo; string to find out the spelling of the country in the dataset, and we input that country name when defining the dataframe of the product space (&rsquo;df<sub>ps</sub>&rsquo;).\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Find out what 'location_name_short_en corresponds to Saudi Arabia\nSTRING = 'audi'\ndf_rca[df_rca['location_name_short_en'].str.contains(STRING)][['location_name_short_en']].drop_duplicates()\n# result: Saudi Arabia'"]},{"cell_type":"markdown","metadata":{},"source":["##### Country, RCA, year, export value selections\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Next we define what trade properties of Saudi Arabia we want to visualize. The example below visualizes specialiation in 2005 (year=2005, RCAcpt>=1) of only those products with at least 40 million in trade value.\n\nThis is outside of the product space function so you can inspect the dataframe before plotting.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Select country\nCOUNTRY_STRING = 'Saudi Arabia'\ndf_ps = df_rca[df_rca['location_name_short_en']==COUNTRY_STRING].copy()\n\n# Cross-check\nif df_ps.shape[0] == 0:\n    print('Country string set above does not exist in data, typed correctly?')\n    STOP\n\n# Select year\ndf_ps = df_ps[df_ps['year']==2005].copy()\n\n# Select RCA >= 1\ndf_ps = df_ps[df_ps['RCAcpt']>=1]\n\n# Keep only relevant columns\ndf_ps = df_ps[['hs_product_name_short_en','export_value']]\n\n# Keep only products with minimum value threshold\nexports_min_threshold = 40000000\ndf_ps = df_ps[df_ps['export_value']>exports_min_threshold]\n\n# Show resulting dataframe\ndf_ps.sample(n=5)\n\nprint('ready to plot in product space')"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Plot in the product space\ncreate_product_space(df_plot_dataframe=df_ps,\n                     df_plot_node_col='hs_product_code',\n                     df_node_size_col='export_value',\n                     show_legend = 0)"]},{"cell_type":"markdown","metadata":{},"source":["##### Product space with legend\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Below is a legend of the product space. There&rsquo;s also a &rsquo;show legend&rsquo; option in the &rsquo;create product space&rsquo; function but this option needs to be updated.\n\n![img](https://www.dropbox.com/s/lf4lf8ktqahnovg/Selection_032.png?dl=1)\n\nTo see exactly what node represents what product, use the Atlas for now by hovering with the mouse over a node:\n\n[https://atlas.cid.harvard.edu/explore/network?country=186&year=2018&productClass=HS&product=undefined&startYear=undefined&target=Product&partner=undefined](https://atlas.cid.harvard.edu/explore/network?country=186&year=2018&productClass=HS&product=undefined&startYear=undefined&target=Product&partner=undefined)\n\n(This can also be implemented through Python by exporting to html instead of as an image, but not implemented above yet)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## -----------&#x2013;&#x2014; Break: Assignment 1 ------------------\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### What product does Ukraine export most in 1995? (excluding services such as &rsquo;transport&rsquo;, &rsquo;ict&rsquo; etc)\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["### What products is Ukraine specialized in in 1995 and 2005 and how much do they export of these?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["### Which product is most related to the product &rsquo;Stainless steel wire&rsquo;?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["### Plot Ukraine in the product space in 1995.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["How would you characterize Ukraine&rsquo;s position in the product space?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["### Plot Ukraine in the product space in 2015.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Do you notice a difference with 1995?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["### Plot your own country across different years in the product space. Do the results make sense? Do you notice any patterns?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["## Predicting diversification of countries: densities / density regressions\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Does a country&rsquo;s position in the the product space predict what products it diversifies into in the future? Indeed it does, according to Hidalgo et al. (2007) and many other studies that have followed. If a product is in close proximity to your current (export) basket of products, you are more likely to diversify into that product as a result: monkeys can only jump to the nearest branch in a tree.\n\n(You can also see this for yourself using the code above, by plotting the same country in the product space across subsequent years. Best done using the SITC trade classification that goes back further in time into the 1970s, rather than the HS classification used above which starts only in 1995).\n\nTo test this empirically, one can perform so called &rsquo;density regressions&rsquo;.\n\nFor every possible country-product combination, you calculate the extent to which one&rsquo;s existing product portfolio is proximate (using the product proximities calculated earlier) to it, which is refered to as &rsquo;density&rsquo;.\n\nYou then test whether density predicts whether country-product combinations that were not present in $t$ are actually present in $t + 1$.\n\nWe will do so below.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Prepare product-product-proximity matrix, all years\n\n"]},{"cell_type":"markdown","metadata":{},"source":["First we create a matrix of all possible product combinations in all years and we add proximities to it (we take the earlier product proximity matrix that we created, which was done using 1995 data, and make sure it also contains proximities to products that were not present at all in 1995. To avoid calculation problems with missing values later).\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Create product * product matrix and add proximity for each product\n# -- in long format\nproducts = df_rca['hs_product_name_short_en'].unique()\ncombs = list(combinations(products,2))\ndf_pp = pd.DataFrame(combs,columns=['product_1','product_2'])\n# df_pp.shape # should be N products * N products\n\n# make it asymmetrical\ndft = df_pp.copy()\ndft.rename(columns={f'product_2':f'product_1t'}, inplace=True)\ndft.rename(columns={f'product_1':f'product_2'}, inplace=True)\ndft.rename(columns={f'product_1t':f'product_1'}, inplace=True)\ndf_pp = pd.concat([df_pp,dft],axis=0)\n\n# add proximities\ndf_pp = pd.merge(df_pp,df_cppt[['product_1','product_2','phi']],how='left',on=[f'product_1','product_2'])\n\n# set proximity to 0 if missing (preferably all products are in matrix)\ndf_pp.loc[df_pp['phi'].isnull(),'phi'] = 0\n\nprint('product-product proximity matrix for all years ready')"]},{"cell_type":"markdown","metadata":{},"source":["### Calculate density\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Next, for each country, we take the portfolio of underdeveloped or (&rsquo;not present&rsquo;) products in $t$ (1996 in the example below).\n\nFollowing Hidalgo et al (2007) we define:\n\n-   &rsquo;underdeveloped&rsquo; as those country-product combinations with with RCA < 0.5.\n-   &rsquo;developed&rsquo; as those country-product combinations with an RCA > 1.\n\n(Those with RCAs between 0.5 and 1 Hidalgo et al refer to as &rsquo;inconclusive&rsquo;)\n\nWe then use this information in conjunction with the product proximity matrix above to calculate density following Hidalgo et al:\n\n\\begin{equation} \\label{density}\n\\omega_{cj} = \\frac{\n\\sum \\limits_{i} \\chi_{i} \\phi_{ij}\n}\n{\\sum \\limits_{i} \\phi_ij }\n\\tag{7}\n\\end{equation}\n\nwhere $\\omega_{ci}$ is the density around product $j$ for the $c^_th$ country, $\\chi_{i}$ = 1 if RCA >= 1 and 0 otherwise, and $\\phi_{ij}$ is the matrix of conditional proximities between products that we created earlier.\n\nA density of 0.44 would imply that 44% of the neighbouring space of the product seems to be developed in the country.\n\nFor each product-country combination that is &rsquo;underdeveloped&rsquo;, we will create a density value below.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"#+begin_example\nDone region 10 out of 220\nDone region 20 out of 220\nDone region 30 out of 220\nDone region 40 out of 220\nDone region 50 out of 220\nDone region 60 out of 220\nDone region 70 out of 220\nDone region 80 out of 220\nDone region 90 out of 220\nDone region 100 out of 220\nDone region 110 out of 220\nDone region 120 out of 220\nDone region 130 out of 220\nDone region 140 out of 220\nDone region 150 out of 220\nDone region 160 out of 220\nDone region 170 out of 220\nDone region 180 out of 220\nDone region 190 out of 220\nDone region 200 out of 220\nDone region 210 out of 220\ncountry-product densities finished for year 1996\n#+end_example"}],"source":["def calc_density_hidalgo_et_al(rca_dataframe=None,\n                 region_col = None,\n                 product_col = None,\n                 rca_col = None,\n                 year = None,\n                 underdeveloped_maximum_rca_threshold = 0.5,\n                 developed_minimum_rca_threshold = 1):\n\n    \"\"\"\n    Calculaties densities for product-country combinations.\n\n    Returns a pandas dataframe.\n\n    \"\"\"\n\n    # Keep only country-product information in year specified\n    df_d = rca_dataframe[rca_dataframe['year']==year].copy()\n\n    # drop if countries have 0 exports in whole year\n    # - don't calculate densities for these: error in data\n    df_d['exports_sum'] = df_d.groupby([region_col])['export_value'].transform('sum')\n    df_d = df_d[df_d['exports_sum']!=0]\n\n    # Keep only necessary columns\n    df_d = df_d[[region_col,product_col,rca_col]]\n\n    # This will be the country-product density dataframe to which densities are appended below\n    df_cpd = pd.DataFrame()\n\n    # We will loop over regions (countries) to save memory\n    REGIONS = df_d[region_col].unique()\n    indexL = 10\n    for index,REGION in enumerate(REGIONS):\n        if index == indexL:\n            print(f'Done region {index} out of {len(REGIONS)}')\n            indexL = indexL + 10\n        df_dc = df_d[df_d[region_col]==REGION].copy()\n\n        # For the sake of completion: we want to add all products to the matrix: products that\n        # have not (yet) been present in a country are now not in the rca matrix\n        # We thus use the pp-matrix for this\n        products_exclude_from_not_developed = df_dc[df_dc[rca_col]>=underdeveloped_maximum_rca_threshold][product_col].unique()\n        products_not_developed = [x for x in df_pp['product_1'].unique() if x not in products_exclude_from_not_developed]\n\n        # Merge this into proximity matrix (in long form)\n        # -- keep only proximities for those products in the country's 'underdeveloped' portfolio\n        df_ppt = df_pp[df_pp['product_1'].isin(products_not_developed)].copy()\n\n        # now add products the country does have developed (RCA >= 1 in t)\n        df_developed = df_dc[df_dc['RCAcpt']>=developed_minimum_rca_threshold]\n        dft = pd.merge(df_ppt,df_developed,how='left',left_on='product_2',right_on=product_col)\n        dft.rename(columns={f'RCAcpt':f'RCAcpt_product2'}, inplace=True)\n\n        # Density includes only those products 'developed/present' products (RCA > 1)\n        dft['phi_include'] = 0\n        dft.loc[ (dft['RCAcpt_product2']>1),'phi_include'] = dft['phi']\n\n        # Take the sum of these for product 1\n        dft['density_sum'] = dft.groupby(['product_1'])['phi_include'].transform('sum')\n\n        # Divide this density_sum by sum of all densities as in Hidalgo et al\n        dft['density_sum_all'] = dft.groupby(['product_1'])['phi'].transform('sum')\n        dft['density'] = dft['density_sum'] / dft['density_sum_all']\n        dft.loc[dft['density'].isnull(),'density'] = 0 # 0 if missing, no sum\n\n        # Now drop information on product 2: keep only one observation per product 1\n        dft.drop_duplicates(subset='product_1',inplace=True)\n\n        # add region information again\n        dft[region_col] = REGION\n\n        # Keep only relevant columns\n        dft = dft[[region_col,'product_1','density']]\n\n        # add to country-product density dataframe\n        df_cpd = pd.concat([df_cpd,dft],axis=0)\n\n    print(f'country-product densities finished for year {year}')\n\n    return df_cpd\n\n# -- Create country-product densities dataframe\n# Loop over countries now, takes about 2 minutes\ndf_cpd = calc_density_hidalgo_et_al(rca_dataframe=df_rca,\n                 region_col = 'location_name_short_en',\n                 product_col = 'hs_product_name_short_en',\n                 rca_col = 'RCAcpt',\n                 year = 1996,\n                 underdeveloped_maximum_rca_threshold = 0.5,\n                 developed_minimum_rca_threshold = 1)"]},{"cell_type":"markdown","metadata":{},"source":["### Add information on product diversification of countries in t + 1\n\n"]},{"cell_type":"markdown","metadata":{},"source":["For each country we now have a vector of underdeveloped products and their corresponding density. Next we add information on whether countries actually developed those products in $t + 1$ (i.e. if they have an RCA >= 1 in $t + 1$).\n\nWe will use 2005 as $t + 1$ below.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Now add information on whether these products are present 10 years later\n# -- again using the rca matrix\ndf_future = df_rca[df_rca['year']==2005].copy()\n\n# keep only relevant columns\ndf_future = df_future[['location_name_short_en','hs_product_name_short_en','RCAcpt','export_value']]\n\n# tag and drop countries with no exports at all: error in data\ndf_future['exports_sum'] = df_future.groupby('location_name_short_en')['export_value'].transform('sum')\ndf_cpdf = pd.merge(df_cpd,df_future,how='left',left_on=[f'location_name_short_en',f'product_1'],right_on=['location_name_short_en','hs_product_name_short_en'],indicator=True)\ndf_cpdf = df_cpdf[df_cpdf['exports_sum']!=0] # (none in 2005 when dropped in 1996 density calculations)\n\n# Remove those with RCA between 0.5 and 1: 'inconclusive' in Hidalgo et al 2007\ndf_cpdf = df_cpdf[ (df_cpdf['RCAcpt']<0.5) | (df_cpdf['RCAcpt']>1) ]\n\n# Tag if product was developed or not\ndf_cpdf['present'] = 0\ndf_cpdf.loc[df_cpdf['RCAcpt']>=1,'present'] = 1"]},{"cell_type":"markdown","metadata":{},"source":["### Plot density distribution\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Below we plot the density distribution in $t + 1$ of not-developed and developed products.\n\nDensity is generally higher for those products that were developed between $t$ and $t + 1$ than for those that were not.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["dfa = pd.DataFrame()\nfor present in [0,1]:\n    dft = df_cpdf[df_cpdf['present']==present].copy()\n    dft.shape\n    #dfo = pd.DataFrame([0])\n    li = []\n    for x in range(1,11,1):\n        x_min = (x/10)-0.1\n        x_max= (x/10)\n        if x_max == 1:\n            x_max = 1.01\n        sh_in_density = dft[ (dft['density']>=x_min) & (dft['density']<x_max)].shape[0]/dft.shape[0]\n        li.append([f'{round(x_min,2)}-{round(x_max,2)}', sh_in_density])\n    dfo = pd.DataFrame(li)\n    dfo.index=dfo[0]\n    dfo.drop(0,axis=1,inplace=True)\n    dfo.rename(columns={1:f'{present}'}, inplace=True)\n    dfa = pd.concat([dfa,dfo],axis=1)\n\ndfa.rename(columns={'0':f'not_developed'}, inplace=True)\ndfa.rename(columns={'1':f'developed'}, inplace=True)\ndfa.plot.bar()"]},{"cell_type":"markdown","metadata":{},"source":["### Density regression\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Finally we run a simple density regression. We will use the &rsquo;statsmodels&rsquo; package in Python for this (imported at the beginning of the notebook in the first code cell).\n\nDifferent packages are available for this in Python, linearmodels, statsmodels, panelOLS (but removed from pandas), and so on.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Define X and Y columns / arrays from dataframe\nX_cols = ['density']\nY_col = ['present']\n# sub-select the columns\nX = df_cpdf[X_cols]\nY = df_cpdf[Y_col]\n# Add constant\nX = sm.add_constant(X)\nmodel = sm.OLS(Y,X)\nresults = model.fit()\n# Show results\nprint(results.summary())"]},{"cell_type":"markdown","metadata":{},"source":["(To get stronger results, one could also include only the closest-occupied products&rsquo; proximity, for instance (see Hidalgo et al&rsquo;s 2007 Supplementary Section).)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Model with fixed effects\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Including dummies\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Include FE by including dummies for the variable in question.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Country fixed effects in statsmodels\ncountries_d = pd.get_dummies(df_cpdf['location_name_short_en'],drop_first=True)\n# add 'd_' in front of variables\ncountries_d.columns = ['d_'+col for col in countries_d.columns]\n# add dummies to main dataframe\ndf_cpdf2 = pd.concat([df_cpdf,countries_d],axis=1)\n##\nX_cols = ['density'] + [col for col in df_cpdf2.columns if 'd_' in col]\nY_col = ['present']\n##\nX = df_cpdf2[X_cols]\nY = df_cpdf2[Y_col]\n# Add constant\nX = sm.add_constant(X)\nmodel = sm.OLS(Y,X)\nprint(f'fitting')\nresults = model.fit()\nprint(f'ready')\n# Show results\nprint(results.summary())"]},{"cell_type":"markdown","metadata":{},"source":["#### Demeaning\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Much faster: One can also demean instead of including dummies, as done below.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# (better to do this in STATA)\nMEAN = df_cpdf['density'].mean()\ndf_cpdf2 = df_cpdf - df_cpdf.groupby(df_cpdf['location_name_short_en']).transform('mean') + MEAN\n##\nX_cols = ['density']\nY_col = ['present']\n##\nX = df_cpdf2[X_cols]\nY = df_cpdf2[Y_col]\n# Add constant\nX = sm.add_constant(X)\nmodel = sm.OLS(Y,X)\nprint(f'fitting')\nresults = model.fit()\nprint(f'ready')\n# Show results\nprint(results.summary())"]},{"cell_type":"markdown","metadata":{},"source":["(Adjust standard errors afterwards).\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Calculating Economic Complexity / Product Complexity using trade data\n\n"]},{"cell_type":"markdown","metadata":{},"source":["We know from the product space and density regressions how products are related to one another and how that matters for diversification of countries.\n\nThe next step is to look at which parts of the product space are most interesting to ultimately reach / diversify into. Generally complex products are located in the center of the product space, and countries with a higher economic complexity tend to have higher economic growth.\n\n![img](imgs/complex_products_in_product_space.png)\n\n![img](https://www.dropbox.com/s/a231jw76yocjkkr/complex_products_in_product_space.png?dl=1)\n\nRecall from the lecture that the economic complexity index (ECI) and product complexity index (PCI) measures are derived from an iterative method of reflections algorithm on country diversity and product ubiquity (Hidalgo Hausmann 2009), or finding the eigenvalues of a country-product matrix (Mealy et al. 2019)\n\n![img](/home/linux/Dropbox/proj/org_zhtml_projects/product-space-eci-workshop/imgs/countries_products_eci.png)\n\n![img](https://www.dropbox.com/s/dte4vwgk4tvj3rd/countries_products_eci.png?dl=1)\n\nWe can calculate these in Python on raw data using the &rsquo;py-ecomplexity&rsquo; package (by Shreyas Gagdgin Matha at the Growth Lab, available at [https://github.com/cid-harvard/py-ecomplexity](https://github.com/cid-harvard/py-ecomplexity)). A STATA package of this is available at:\n\n[https://github.com/cid-harvard/ecomplexity](https://github.com/cid-harvard/ecomplexity)\n\nOne can also directly download the PCI value for every product from the Atlas data repository - the ECI of a country is the mean of the PCI values of the products it has a comparative advantage in.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Using the &rsquo;py-ecomplexity&rsquo; package\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Installation\n\n"]},{"cell_type":"markdown","metadata":{},"source":["One can install it by pointing pip (to install python packages) to the respective library on github, using the following command:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["!pip install ecomplexity\nprint('installed py-ecomplexity')"]},{"cell_type":"markdown","metadata":{},"source":["#### Usage\n\n"]},{"cell_type":"markdown","metadata":{},"source":["We will again use again the original trade dataset (df\\\\<sub>orig</sub>), below.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from ecomplexity import ecomplexity\nfrom ecomplexity import proximity\n\n# To use py-ecomplexity, specify the following columns\ntrade_cols = {'time':'year',\n              'loc':'location_name_short_en',\n              'prod':'hs_product_name_short_en',\n              'val':'export_value'}\n              \n# Then run the command\nprint('calculating ecomplexity')\ndf_ec = ecomplexity(df_orig, trade_cols)\nprint('finished calculating')\n\n# Keep selected columns\ndf_ec = df_ec[['location_name_short_en',\n               'hs_product_name_short_en',\n               'export_value',\n               'year',\n               'pci',\n               'eci']]\n\n# Show results\ndf_ec.sample(n=10)"]},{"cell_type":"markdown","metadata":{},"source":["## -----------&#x2013;&#x2014; Break: Assignment ------------------\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### What are countries with high complexity in 2015?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["### Vice versa, what are countries with low complexity in 2015?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["### What are products (PCI) with high complexity in 2015?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["### Vice versa, what are products (PCI) with low complexity in 2015?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["### Ukraine\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### How did Ukraine&rsquo;s economic complexity evolve over time?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["#### How does Ukraine&rsquo;s economic complexity in 2015 compare to other countries? Which countries have comparable economic complexity?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["#### What are the most complex products that Ukraine exported in 2015?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{},"source":["## ---\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## ---\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## ---\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Assignments answers\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Assignment 1:\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### What product does Ukraine export most in 1995? (excluding services such as &rsquo;transport&rsquo;, &rsquo;ict&rsquo; etc)\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df2 = df_orig[ (df_orig['location_name_short_en']=='Ukraine') & (df_orig['year'] == 2005) ].copy()\ndf3 = df2.groupby(['hs_product_code','hs_product_name_short_en'],as_index=False)['export_value'].sum()\ndf3.sort_values(by=['export_value'],ascending=False,inplace=True)\ndf3[['hs_product_name_short_en','export_value']][0:5]"]},{"cell_type":"markdown","metadata":{},"source":["#### What products is Ukraine specialized in in 1995 and 2005 and how much do they export of these?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# 1995\n\n# Use the 'df_rca' dataframe for this\n\ndf2 = df_rca[ (df_rca['year']==1995) & (df_rca['location_name_short_en']=='Ukraine')].copy()\ndf2.sort_values(by=['RCAcpt'],ascending=False,inplace=True)\ndf2[['hs_product_name_short_en','RCAcpt','year','export_value']][0:5]\n\n# 2005\ndf2 = df_rca[ (df_rca['year']==2005) & (df_rca['location_name_short_en']=='Ukraine')].copy()\ndf2.sort_values(by=['RCAcpt'],ascending=False,inplace=True)\ndf2[['hs_product_name_short_en','RCAcpt','year','export_value']][0:5]"]},{"cell_type":"markdown","metadata":{},"source":["#### Which product is most related to the product &rsquo;Stainless steel wire&rsquo;?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["PRODUCT = 'Stainless steel wire'\n# select only this product\ndft = df_cppt[df_cppt['product_1']==PRODUCT].copy()\n# Sort from high to low y Crtp\ndft.sort_values(by=['phi'],ascending=False,inplace=True)\n# Show only first row\ndft[0:1]"]},{"cell_type":"markdown","metadata":{},"source":["#### Plot Ukraine in the product space in 1995.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["How would you characterize Ukraine&rsquo;s position in the product space?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Select country\nCOUNTRY_STRING = 'Ukraine'\ndf_ps = df_rca[df_rca['location_name_short_en']==COUNTRY_STRING].copy()\n\n# Cross-check\nif df_ps.shape[0] == 0:\n    print('Country string set above does not exist in data, typed correctly?')\n    STOP\n\n# Select year\ndf_ps = df_ps[df_ps['year']==1995].copy()\n#df_ps = df_ps[df_ps['year']==2005].copy()\n\n# Select RCA >= 1\ndf_ps = df_ps[df_ps['RCAcpt']>=1]\n\n# Keep only relevant columns\ndf_ps = df_ps[['hs_product_name_short_en','export_value']]\n\n# Keep only products with minimum value threshold\nexports_min_threshold = 40000000\ndf_ps = df_ps[df_ps['export_value']>exports_min_threshold]\n\n# Show resulting dataframe\ndf_ps.sample(n=5)\n\n# And finally plot in the product space\ncreate_product_space(df_plot_dataframe=df_ps,\n                     df_plot_node_col='hs_product_code',\n                     df_node_size_col='export_value')\nprint('plotted')"]},{"cell_type":"markdown","metadata":{},"source":["#### Plot Ukraine in the product space in 2015.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Do you notice a difference with 1995?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Select country\nCOUNTRY_STRING = 'Ukraine'\ndf_ps = df_rca[df_rca['location_name_short_en']==COUNTRY_STRING].copy()\n\n# Cross-check\nif df_ps.shape[0] == 0:\n    print('Country string set above does not exist in data, typed correctly?')\n    STOP\n\n# Select year\ndf_ps = df_ps[df_ps['year']==2015].copy()\n#df_ps = df_ps[df_ps['year']==2005].copy()\n\n# Select RCA >= 1\ndf_ps = df_ps[df_ps['RCAcpt']>=1]\n\n# Keep only relevant columns\ndf_ps = df_ps[['hs_product_name_short_en','export_value']]\n\n# Keep only products with minimum value threshold\nexports_min_threshold = 40000000\ndf_ps = df_ps[df_ps['export_value']>exports_min_threshold]\n\n# Show resulting dataframe\ndf_ps.sample(n=5)\n\n# And finally plot in the product space\ncreate_product_space(df_plot_dataframe=df_ps,\n                     df_plot_node_col='hs_product_code',\n                     df_node_size_col='export_value',\n                     show_legend = 0)\nprint('plotted')"]},{"cell_type":"markdown","metadata":{},"source":["#### Plot your own country across different years in the product space. Do the results make sense? Do you notice any patterns?\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Assignment 2:\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### What are countries with high complexity in 2015?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["qt_high = df_ec[df_ec['year']==2015]['eci'].quantile(0.95)\ndf_ec[df_ec['eci']>qt_high][['location_name_short_en']].drop_duplicates()[0:10]"]},{"cell_type":"markdown","metadata":{},"source":["#### Vice versa, what are countries with low complexity in 2015?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["qt_low = df_ec[df_ec['year']==2015]['eci'].quantile(0.05)\ndf_ec[df_ec['eci']<qt_low][['location_name_short_en']].drop_duplicates()[0:10]"]},{"cell_type":"markdown","metadata":{},"source":["#### What are products (PCI) with high complexity in 2015?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["qt_high = df_ec[df_ec['year']==2015]['pci'].quantile(0.95)\ndf_ec[df_ec['pci']>qt_high][['hs_product_name_short_en']].drop_duplicates()[0:10]"]},{"cell_type":"markdown","metadata":{},"source":["#### Vice versa, what are products (PCI) with low complexity in 2015?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["qt_low = df_ec[df_ec['year']==2015]['pci'].quantile(0.05)\ndf_ec[df_ec['pci']<qt_low][['hs_product_name_short_en','pci']].drop_duplicates()[0:10]"]},{"cell_type":"markdown","metadata":{},"source":["#### Ukraine\n\n"]},{"cell_type":"markdown","metadata":{},"source":["##### How did Ukraine&rsquo;s economic complexity evolve over time?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df = df_ec[df_ec['location_name_short_en']=='Ukraine']\n# drop duplicates of products\ndf.drop_duplicates(subset=['location_name_short_en','year'],inplace=True)\n# keep relevant columns\ndf = df[['location_name_short_en','year','eci']]\n# sort by ECI\ndf.sort_values(by='year',ascending=False,inplace=True)\ndf.reset_index(inplace=True,drop=True)\ndf.plot(x='year', y='eci')"]},{"cell_type":"markdown","metadata":{},"source":["##### How does Ukraine&rsquo;s economic complexity in 2015 compare to other countries? Which countries have comparable economic complexity?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df = df_ec[df_ec['year']==2015].copy()\n# drop duplicates of countries\ndf = df[['location_name_short_en','eci']].drop_duplicates()\n# sort by ECI\ndf.sort_values(by='eci',ascending=False,inplace=True)\ndf.reset_index(inplace=True,drop=True)\n# create rank variable\ndf['rank'] = df.index\n# get rank of Ukraine\nRANK_UKRAINE = df[df['location_name_short_en']=='Ukraine'].reset_index()['rank'][0]\n# check countries ranked directly above and below Ukraine\ndf[ (df['rank']>RANK_UKRAINE-10) & (df['rank']<RANK_UKRAINE+10)]"]},{"cell_type":"markdown","metadata":{},"source":["##### What are the most complex products that Ukraine exported in 2015?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["df = df_ec[df_ec['location_name_short_en']=='Ukraine'].copy()\ndf = df[df['year']==1995]\ndf.sort_values(by=['pci'],ascending=False,inplace=True)\ndf.reset_index(inplace=True,drop=True)\ndf[0:10][['hs_product_name_short_en','pci']]"]}],"metadata":{"org":null,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}
